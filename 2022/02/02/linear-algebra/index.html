<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Tengjun的个人技术博客">
    <meta name="keyword"  content="BMI">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        线性代数中的几何 (Geometry in Linear Algebra) - Tengjun的个人技术博客 | 脑机接口-BMI
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 5.4.0"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 记录自己在探索脑机接口技术中的点滴 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar radius">
            <img src="/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>Tengjun Liu</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86"><span class="toc-text">0. 前置知识</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rn-%E4%B8%AD%E7%9A%84%E5%90%91%E9%87%8Fvector"><span class="toc-text">1. \(R^n\)
中的向量（Vector）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E7%9A%84%E8%BF%90%E7%AE%97%E5%8F%8A%E5%85%B6%E5%87%A0%E4%BD%95%E8%A1%A8%E7%A4%BA"><span class="toc-text">2. 向量的运算及其几何表示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E7%A9%BA%E9%97%B4-span"><span class="toc-text">3. 生成空间 （Span）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E6%96%B9%E7%A8%8B-matrix-equations"><span class="toc-text">4. 矩阵方程 （Matrix Equations）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E7%8B%AC%E7%AB%8Blinear-independence"><span class="toc-text">5. 线性独立（Linear
Independence）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%90%E7%A9%BA%E9%97%B4%E5%88%97%E7%A9%BA%E9%97%B4%E9%9B%B6%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%9F%BAsubspace-column-space-null-space-and-basis"><span class="toc-text">6.
子空间、列空间、零空间与基（Subspace, Column Space, Null Space and
Basis）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%8F%98%E6%8D%A2matrix-transformations"><span class="toc-text">7. 矩阵变换（Matrix
Transformations）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95matrix-multiplication"><span class="toc-text">8. 矩阵乘法（Matrix
Multiplication）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E7%9A%84%E9%80%86matrix-inverses"><span class="toc-text">9. 矩阵的逆（Matrix Inverses）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8Fdeterminant"><span class="toc-text">10. 行列式（Determinant）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8E%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8Feigenvalues-and-eigenvectors"><span class="toc-text">10.
特征值与特征向量（Eigenvalues and Eigenvectors）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E4%BA%A4%E6%80%A7orthogonality"><span class="toc-text">11. 正交性（Orthogonality）</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 记录自己在探索脑机接口技术中的点滴 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        

<div class="post-container">
    <div class="post-title">
        线性代数中的几何 (Geometry in Linear Algebra)
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2022-02-02 20:13:29</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#基本数学" title="基本数学">基本数学</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h2 id="前置知识">0. 前置知识</h2>
<p>理解 <span class="math inline">\(R^n\)</span>
（n维向量空间），增广矩阵（augmented
matrix），主元（pivot），自由变量（free
variable），维度（Dimension），标量（scalar）与向量（vector）的区别，知道向量、矩阵运算规则，大致知道子空间（Subspace）、基（Basis）、标准基（standard
basis）、可逆矩阵（invertible
matrix）等概念。其实最好就是上过照本宣科的线代课，对基本概念都有一些了解，想要从几何角度来加深对线代的理解，就可以看看这篇博客。<br></p>
<h2 id="rn-中的向量vector">1. <span class="math inline">\(R^n\)</span>
中的向量（<strong>Vector</strong>）</h2>
<p>首先从最基本的概念讲起。一个n维向量在几何上有两种解释：一种是它是n维空间里的一个点（point），另一种则是向量（vector），如下图所示。<br>
<img src="la-1.png" /><br>
在之后的描述中，除非特别声明，否则默认向量起始于原点。但需要注意的是，这只是为了描述的方便，向量在可以在空间中任意位置，它并不一定要以原点为起点。换句话说，一个向量只由它的长度和方向决定，与其位置无关。<br>
当然，向量也可以表示两个点之间的距离，如下图所示。<br> <img
src="la-2.png" /><br></p>
<h2 id="向量的运算及其几何表示">2. 向量的运算及其几何表示</h2>
<p>向量的相加减结果可由向量间各个维度数值各自相加减得到，如下图所示。<br>
<img src="la-3.png" /><br>
而标量与向量的乘法结果可由标量与向量各个维度数值相乘得到，如下图所示。<br>
<img src="la-4.png" /><br>
所以，从几何角度上看，向量间的线性组合，由各个向量各自的缩放（与标量相乘），再将它们相加得到。
而向量的线性组合又能反映代数上的什么东西呢？假设有这么一个方程（向量方程，即由向量构成的方程，等价于一个线性代数方程）：<br>
<img src="la-5.png" /><br> 那么我们所要求的解（ <span
class="math inline">\(x\)</span> 与 <span
class="math inline">\(y\)</span>
），是不是就是两个向量的缩放因子？换句话说，一个向量方程（线性代数方程）有解即意味着等号右边的向量是等号左边向量们的线性组合，而解就是线性组合中的缩放因子。<br></p>
<h2 id="生成空间-span">3. 生成空间 （<strong>Span</strong>）</h2>
<p>生成空间是一个很重要的概念。简单来说，对于一组向量，以他们为基能张成（线性组合而成）的空间就称为它们的生成空间，可记为：<br>
<img src="la-6.png" /><br> 其中 <span class="math inline">\(x_1\)</span>
到 <span class="math inline">\(x_k\)</span>
为标量（缩放因子），<strong><span
class="math inline">\(v_1\)</span></strong> 到 <strong><span
class="math inline">\(v_k\)</span></strong> 为基向量。<br> 以在 <span
class="math inline">\(R^3\)</span>
中为例，一个向量张成的生成空间为一条一维直线，两个不共线的向量张成的生成空间为一个二维平面，三个不共线且不都在一个平面上的向量张成的生成空间则为一个三维空间，而三个不共线但在一个平面内的向量张成的生成空间则为一个二维平面，如下图所示。<br>
<img src="la-7.png" /><br>
结合上面线性组合相关的讨论，我们又可知道由一组基向量以及它们的生成空间中的任意向量组成的向量方程（代表着一个线性代数方程）有解。<br></p>
<h2 id="矩阵方程-matrix-equations">4. 矩阵方程 （Matrix Equations）</h2>
<p>首先回忆一下，一个矩阵 <strong><span
class="math inline">\(A\)</span></strong> 乘上一个向量 <strong><span
class="math inline">\(x\)</span></strong> ，可以视为矩阵 <strong><span
class="math inline">\(A\)</span></strong> 中各向量与向量 <strong><span
class="math inline">\(x\)</span></strong>
中各元素的线性组合，如下公式所示。<br> <img src="la-8.png" /><br> 其中
<span class="math inline">\(x_1\)</span> 到 <span
class="math inline">\(x_n\)</span> 为标量（缩放因子），<strong><span
class="math inline">\(v_1\)</span></strong> 到 <strong><span
class="math inline">\(v_n\)</span></strong> 为向量。所以显然，向量
<strong><span class="math inline">\(x\)</span></strong>
中元素的数目应与矩阵 <strong><span
class="math inline">\(A\)</span></strong> 中向量的数目相等，即对于
<strong><span class="math inline">\(Ax = b\)</span></strong> 而言，矩阵
<strong><span class="math inline">\(A\)</span></strong> 的列数应与
<strong><span class="math inline">\(x\)</span></strong> 维度一致。而这个
<strong><span class="math inline">\(Ax = b\)</span></strong>
就被定义为<strong>矩阵方程</strong> （<strong>Matrix
Equation</strong>)，其中向量 <strong><span
class="math inline">\(x\)</span></strong>
中各元素大小未知（想想与向量方程的关系？是不是两者是等价且可以相互转换的？）。这也是线性系统的另一种表达方式。<br>
总结一下，目前为止，结合代数中的内容，我们就有四种方式来思考一个线性系统：<br>
1. 线性代数方程组（代数角度）；<br> 2. 增广矩阵（代数角度）；<br> 3.
向量方程（几何角度）；<br> 4. 矩阵方程（几何角度）。<br></p>
<p>上面我们解释了矩阵方程与向量线性组合的关系，再回头看我们之前讨论的线性组合与生成空间的关系，是不是发现又可以串起来了？也就是说，当且仅当向量
<strong><span class="math inline">\(b\)</span></strong> 在矩阵
<strong><span class="math inline">\(A\)</span></strong>
中各向量张成的生成空间里， <strong><span class="math inline">\(Ax =
b\)</span></strong>
有解。其实这就搭起了代数中方程有解与几何中生成空间的桥梁。下面给一个直观的例子。<br>
假如我们要求 <strong><span class="math inline">\(Ax =
b\)</span></strong> 是否有解？对于： <span class="math display">\[
\mathbf{A}  = \begin{pmatrix}
2 &amp; 1\\
-1 &amp; 0\\
1 &amp; -1
\end{pmatrix},
\mathbf{b} = \begin{pmatrix}
0\\
2\\
2
\end{pmatrix}
\]</span> 由上面我们的讨论可知，当且仅当向量 <strong><span
class="math inline">\(b\)</span></strong> 在矩阵 <strong><span
class="math inline">\(A\)</span></strong> 中各向量张成的生成空间里，
<strong><span class="math inline">\(Ax = b\)</span></strong>
有解。所以在下图中我们将 <strong><span
class="math inline">\(A\)</span></strong>
中各向量张成的生成空间（紫色）与 <strong><span
class="math inline">\(b\)</span></strong> （黑色箭头）画出，可见
<strong><span class="math inline">\(b\)</span></strong> 并不在
<strong><span class="math inline">\(A\)</span></strong>
中各向量张成的生成空间中，所以方程无解。<br> <img src="la-46.png" /><br>
接下来我们考虑 <strong><span class="math inline">\(Ax =
b\)</span></strong>
有解的情况，怎么从几何上去表示其解呢？在回答这个问题之前，我们先考虑一个简单一点的例子：如果
<strong><span class="math inline">\(b\)</span></strong>
为零向量时解是什么呢？考虑下面的情况：<br> 假设我们要求 <strong><span
class="math inline">\(Ax = 0\)</span></strong>
的解（这类方程至少有一个平凡解(trivial solution) <strong><span
class="math inline">\(x=0\)</span></strong> ），对于： <span
class="math display">\[
\mathbf{A}  = \begin{pmatrix}
1 &amp; -1 &amp; 2\\
-2 &amp; 2 &amp; -4
\end{pmatrix}
\]</span> 我们用参数化的形式表示它的解，如下所示：<br> <img
src="la-9.png" /><br> 显然我们可以将其转换为向量方程的形式：<br> <img
src="la-10.png" /><br>
所以显然，方程的解为上述两个向量张成的生成空间：<br> <img
src="la-11.png" /><br> 将其可视化如下图所示： <img
src="la-12.png" /><br> 所以从几何角度上看，方程 <strong><span
class="math inline">\(Ax = 0\)</span></strong>
的解可以表示为某个/组向量张成的生成空间，注意区分好与上文中对于
<strong><span class="math inline">\(Ax = b\)</span></strong>
讨论的区别（“解是一个生成空间（解是什么）”与“解在生成空间中（有解的条件）”的区别）。顺带回顾一下变量数目与空间维度的关系：在这个例子中，一共有三个变量（构成
<strong><span class="math inline">\(x\)</span></strong>
），那么方程的解集必在 <span class="math inline">\(R^3\)</span>
或其子空间，而这个例子中只有两个自由变量（free
variable），则解集是在一个二维平面上（自由变量的数目等于解集空间的维度）。<br></p>
<p>接着回到我们之前的问题：假设 <strong><span class="math inline">\(Ax =
b\)</span></strong> 有解，那么它的解如何在几何上表示？它与 <strong><span
class="math inline">\(b\)</span></strong>
为零向量时有什么不同呢？考虑下面情况：<br> <span class="math display">\[
\mathbf{A}  = \begin{pmatrix}
1 &amp; -1 &amp; 2\\
-2 &amp; 2 &amp; -4
\end{pmatrix}，
\mathbf{B} = \begin{pmatrix}
1\\
-2
\end{pmatrix}
\]</span> 类似地，我们可以得到其解为：<br> <img src="la-13.png" /><br>
对比这个结果与上面 <strong><span
class="math inline">\(b\)</span></strong>
为零向量时的结果，显然可以看出，两者相差的只是一个平移( <span
class="math inline">\(x_2\)</span> 与 <span
class="math inline">\(x_3\)</span> 为0时的特解) <strong><span
class="math inline">\(p\)</span></strong> ，如下图所示：<br> <img
src="la-14.png" /><br>
当然，这里举的例子都是方程不是有唯一解的情况，而如果方程只有唯一解，其解在空间上表示就只是一个点了（此时
<strong><span class="math inline">\(Ax = b\)</span></strong> 与
<strong><span class="math inline">\(Ax = 0\)</span></strong>
相差的依然只是一个平移）。<br>
至此，我们在几何角度上又从两个方面去描述一个矩阵方程（ <strong><span
class="math inline">\(Ax = b\)</span></strong> ），注意两者的区别：<br>
1. <strong><span class="math inline">\(Ax = b\)</span></strong>
有解的条件（<strong><span class="math inline">\(b\)</span></strong>
在矩阵 <strong><span class="math inline">\(A\)</span></strong>
中列向量张成的生成空间中，为 <strong><span
class="math inline">\(x\)</span></strong> 选 <strong><span
class="math inline">\(b\)</span></strong>）；<br> 2.
其解集空间（对于确定的 <strong><span
class="math inline">\(b\)</span></strong>，为 <strong><span
class="math inline">\(b\)</span></strong> 选 <strong><span
class="math inline">\(x\)</span></strong>）。</p>
<h2 id="线性独立linear-independence">5. 线性独立（Linear
Independence）</h2>
<p>首先回忆一下线性独立的定义：如果一组向量 <strong><span
class="math inline">\(v_1\)</span></strong> 到 <strong><span
class="math inline">\(v_k\)</span></strong>
，对于下面的方程有且仅有一个平凡解（<span
class="math inline">\(x_1=x_2=...=x_k=0\)</span>），则称它们彼此
<strong>线性独立</strong>。<br> <img src="la-15.png" /><br>
换句话说，就是这组向量中，没有任何一个向量可以由其他向量线性组合得到。下图给出两个
<strong>线性依赖（不独立）</strong> 的例子：<br> <img
src="la-16.png" /><br>
也就是说，从几何角度上看，如果一个向量集合中，有一个向量在其他向量张成的生成空间中，那么这组向量就线性依赖（不独立）；而如果其中任何一个向量都不在其他向量张成的生成空间中，那么这组向量就线性独立。再换个角度想，我们将这些向量一个一个加入向量组中，每加入一个向量组张成的生成空间都增大，那么这组向量就是线性独立的。下面再可视化给出一个线性独立的例子：<br>
<img src="la-17.png" /><br> 而从代数角度上看，矩阵 <strong><span
class="math inline">\(A\)</span></strong>
中各列向量线性独立的条件是化简后每一列都有一个主元（也就是说对于一个列数目大于行数目的矩阵，它必然有线性依赖的列，因为没法做到化简后每一列都有一个主元）。<br></p>
<h2
id="子空间列空间零空间与基subspace-column-space-null-space-and-basis">6.
子空间、列空间、零空间与基（Subspace, Column Space, Null Space and
Basis）</h2>
<p>什么是<strong>子空间</strong>（<strong>Subspace</strong>）？简单地说，子空间就是满足下面三个条件的
<strong><span class="math inline">\(R^n\)</span></strong>
里的一些点构成的子集（<strong>Subset</strong>）：<br> 1.
加法下的封闭性：该子空间中的两个向量相加，结果仍在该子空间中；<br> 2.
标量乘法的封闭性：该子空间中的向量乘上一个标量，其结果仍在该子空间中；<br>
3.
非空性：零向量在这个子空间中（子空间要存在，势必要包含了零向量）。<br></p>
<p>所以显然，由上面的前两个性质，某一子空间中的向量的线性组合（它们的生成空间）结果仍在该子空间中；且由第三个性质，子空间必然会经过原点。换句话说，子空间本身就是一个生成空间，它包含了它之中任何向量张成的生成空间。进一步讲，其本身就是其最大的一个子空间。也就说，随着选中的某一子空间中的向量数目变多，这些向量张成的生成空间也会逐步填满这个子空间。下图给出两个子空间的例子（一维与二维）：<br>
<img src="la-18.png" /><br>
其中黑色箭头表示用于张成生成空间的向量（基向量，下面会进一步讨论），黑点表示原点。下面再给出一些<strong>非</strong>子空间的例子：<br>
<img src="la-19.png" /><br>
其中紫色区域表示定义的“空间”（注意并不是子空间），黑色箭头表示“空间”上的向量，红色箭头表示由“空间”中向量线性组合得到的不在“空间”中的向量。<br>
另外注意区别空间子集（subset）与子空间（subspace）的区别：子空间是一个需要满足上述三个条件的空间子集，也就是空间子集是一个更大的概念。<br>
接下来我们讨论两种重要的子空间：<strong>列空间</strong>（由矩阵
<strong><span class="math inline">\(A\)</span></strong>
中各列向量张成的子空间/生成空间，记作Col( <strong><span
class="math inline">\(A\)</span></strong>
)）与<strong>零空间</strong>（对矩阵 <strong><span
class="math inline">\(A\)</span></strong>，满足 <strong><span
class="math inline">\(Ax=0\)</span></strong>
的解构成的子空间/生成空间，记作Null( <strong><span
class="math inline">\(A\)</span></strong> )）。下面如下矩阵
<strong><span class="math inline">\(A\)</span></strong> 举例：<br> <span
class="math display">\[
\mathbf{A}  = \begin{pmatrix}
1 &amp; 1 \\
1 &amp; 1 \\
1 &amp; 1
\end{pmatrix}
\]</span> 它的列空间可以表示为：<br> <img src="la-20.png" /><br>
它的零空间可以表示为：<br> <img src="la-21.png" /><br>
留意列空间是一条在三维（维度大小与矩阵的行数目相同）空间中的一维（等于矩阵化简后主元的数目）线，零空间是一条在二维（维度大小与矩阵的列数目相同）空间中的一维（等于矩阵化简后自由变量的数目）线。这边又隐含了一个重要的定理：矩阵的列空间的维度与零空间的维度之和为矩阵列的数目，在这个例子中为
<span class="math inline">\(1+1=2\)</span> 。<br>
上面讲完子空间/生成空间，接下来我们讨论子空间/生成空间中的基。为什么需要基的概念，我想最朴素的原因就是数学家们想用最少数量的向量来表征一个生成空间，而基于这个想法，基向量之间就必须相互独立，不然就会有冗余的向量（可以由其他向量线性组合得到）。而对于同一个非零生成空间，它可以有无数组基（比如一个平面，其上任意两个不共线的向量构成它的一组基），但基向量的数目是确定的（由生成空间的维度决定，这其实也是维度的定义）。下图给出了
<span class="math inline">\(R^2\)</span> 的两组基：<br> <img
src="la-22.png" /><br> 其中左图是一组标准基。<br>
那么如何确定列空间的基呢？对于某个矩阵，它的主元（pivot）所在列就构成了它的一组基，如下举例所示，其中RREF（Reduced
row echelon form）表示简化列阶梯形矩阵：<br> <img src="la-23.png" /><br>
也就是说，列空间的基向量的数目（维度）等于矩阵主元的数目。<br>
而如何确定零空间的基呢？将零空间以参数化向量方程表示出来，也可以很轻易得到它的一组基：<br>
<img src="la-24.png" /><br>
类似地，零空间的基向量的数目（维度）等于矩阵自由变量的数目。也就是说，我们从基的角度出发，再次印证了上面给出的一个定理：矩阵的列空间的维度与零空间的维度之和为矩阵列的数目（主元与自由变量数目之和）。下面给出几个图进一步说明这个关系：<br>
<img src="la-26.png" /><br> <img src="la-27.png" /><br> 而其实矩阵的
<strong>秩（rank）</strong>
代表的就是其列空间的维度，零化度（nullity）代表的就是其零空间的维度。也就是说，一个矩阵的秩加上其零化度，等于其列向量的个数（<span
class="math inline">\(rank(\mathbf{A})+nullity(\mathbf{A})=n\)</span>，<span
class="math inline">\(n\)</span> 为矩阵 <span
class="math inline">\(\mathbf{A}\)</span>
的列数目）。再结合之前的讨论，换一个说法就是，一个矩阵的主元的个数加上其解集的维度（自由变量的个数），等于其拥有的变量的总个数。其实这个关系也反映了我们在选择
<strong><span class="math inline">\(Ax = b\)</span></strong> 中的
<strong><span class="math inline">\(x\)</span></strong> 与 <strong><span
class="math inline">\(b\)</span></strong> 的平衡：当我们拥有的选择
<strong><span class="math inline">\(x\)</span></strong>
的自由越多，那么我们拥有的选择 <strong><span
class="math inline">\(b\)</span></strong> 的自由就越少，而这个关系被矩阵
<strong><span class="math inline">\(A\)</span></strong>
中列数目所限定。<br>
而很自然地，当基确定之后，我们就可以基于基构建一个新的坐标系。在笛卡尔坐标系下，<span
class="math inline">\(u_1\)</span> ~ <span
class="math inline">\(u_4\)</span> 的坐标分别为： <span
class="math display">\[
u_1 = [3, -1, 0], u_2 = [-3/2, 1, -3/2], u_3 = [5/2, -3/2, 2], u_4 =
[3/2, 0, -3/2]
\]</span> 现在考虑用 <strong><span class="math inline">\(v_1,
v_2\)</span></strong> 来表示它们，如下图所示：<br> <img
src="la-25.png" /><br> 我们就可以得到以 <strong><span
class="math inline">\(v_1, v_2\)</span></strong> 为基的新坐标系下<span
class="math inline">\(u_1\)</span> ~ <span
class="math inline">\(u_4\)</span> 的坐标：<br> <span
class="math display">\[
u_{1\beta} = [1, 1]， u_{2\beta} = [-1, 1/2], u_{3\beta} = [3/2, -1/2],
u_{4\beta} = [0, 3/2]
\]</span>
由此，相同的几个点在另一个空间中被表示出来，这就完成了一次空间变换。当然，能这么表示的前提是
<span class="math inline">\(u_1\)</span> ~ <span
class="math inline">\(u_4\)</span> 几个点刚好在 <strong><span
class="math inline">\(v_1, v_2\)</span></strong> 的生成空间中。</p>
<h2 id="矩阵变换matrix-transformations">7. 矩阵变换（Matrix
Transformations）</h2>
<p>对于一个<span class="math inline">\(m\)</span>行<span
class="math inline">\(n\)</span>列的矩阵 <strong><span
class="math inline">\(A\)</span></strong> ，其有 <strong><span
class="math inline">\(b=Ax\)</span></strong>
的关系，我们可以将其视为一个变换（Transformation），将自变量
<strong><span class="math inline">\(x\)</span></strong> (维度为<span
class="math inline">\(n\)</span>的向量)，变换为因变量 <strong><span
class="math inline">\(b\)</span></strong> (维度为<span
class="math inline">\(m\)</span>的向量)。顺便再提一下， <strong><span
class="math inline">\(b\)</span></strong> 在矩阵 <strong><span
class="math inline">\(A\)</span></strong>
的列空间中。下图给出一个例子，其中绿色箭头为 <strong><span
class="math inline">\(x\)</span></strong> ，红色箭头为 <strong><span
class="math inline">\(b\)</span></strong> ，中间的矩阵即为 <strong><span
class="math inline">\(A\)</span></strong> ，紫色直线为矩阵 <strong><span
class="math inline">\(A\)</span></strong> 的列空间，也就是说矩阵
<strong><span class="math inline">\(A\)</span></strong>
将一个三维空间（定义域，domain）中的向量 <strong><span
class="math inline">\(x\)</span></strong>
与其列向量进行线性组合，将其变换到一个二维平面（取值空间，codomain）上，但在这个二维平面上
<strong><span class="math inline">\(A\)</span></strong>
的列空间只是一条一维直线（值域，range，其实也就是矩阵 <strong><span
class="math inline">\(A\)</span></strong> 的列空间），上面代表着
<strong><span class="math inline">\(b\)</span></strong>
能分布的空间。<br> <img src="la-28.png" /><br>
这边再给出几个矩阵背后代表的几何意义的例子，最好自己先思考再看之后的答案以加深理解：<br>
如果要将三维空间的点( <strong><span
class="math inline">\(x\)</span></strong>
)投射（projection）到x-y平面上( <strong><span
class="math inline">\(b\)</span></strong> )，那矩阵 <strong><span
class="math inline">\(A\)</span></strong> 应该是什么样子的呢？<br> <img
src="la-29.png" /><br>
那如果要使一个二维平面上的点关于y轴对称呢（Reflection）？<br> <img
src="la-30.png" /><br>
而如果要使一个二维平面上的点保持不变呢（Identity）？<br> <img
src="la-31.png" /><br> 这也是单位矩阵（Identity
Matrix）名字的由来。那如果要将向量进行缩放（Dilation），是不是只需要对单位矩阵乘上一个标量？<br>
接着试着回答一个稍微难一点的问题：如果要将二维平面上的点逆时针旋转90度呢（Rotation）？<br>
<img src="la-32.png" /><br> 留意到这里矩阵 <strong><span
class="math inline">\(A\)</span></strong> 的列向量（[0,1],
[-1,0]）是不是刚好是二维笛卡尔坐标系下基向量（[1,0],[0,1]）逆时针旋转90度的结果呢？<br>
而如果要实现下图所示的在x轴上的错切（shear in the x-direction），矩阵 (
<strong><span class="math inline">\(A\)</span></strong>
)应该是什么样的？<br> <img src="la-33.png" /><br>
可以尝试下面这三个矩阵代表的几何变换分别是什么。<br> <span
class="math display">\[
\mathbf{A_1}  = \begin{pmatrix}
1 &amp; 1 \\
0 &amp; 1
\end{pmatrix},
\mathbf{A_2}  = \begin{pmatrix}
1 &amp; 0 \\
1 &amp; 1
\end{pmatrix},
\mathbf{A_3}  = \begin{pmatrix}
1 &amp; 1 \\
1 &amp; 1
\end{pmatrix}
\]</span> （答案是第一个矩阵代表着上面的变换。）<br>
对于某个矩阵变换，我们还需要留意，其对应的是一个一对一（one-to-one）的变换（换个角度就是，矩阵方程有唯一解或无解/
<strong><span class="math inline">\(Ax=0\)</span></strong>
只有一个平凡解/ 矩阵 <strong><span
class="math inline">\(A\)</span></strong> 的列向量都线性独立/ 矩阵
<strong><span class="math inline">\(A\)</span></strong>
的每一列都有主元/ 矩阵 <strong><span
class="math inline">\(A\)</span></strong>
的列空间（值域）与定义域维度一致），还是一个多对一的变换，注意没有一对多的变换。下面给出几个图解例子：<br>
首先是一个一对一的矩阵变换例子：<br> <img src="la-34.png" /><br>
接着看一个多对一的矩阵变换的例子：<br> <img src="la-35.png" /><br>
这个图中的矩阵 <strong><span class="math inline">\(A\)</span></strong>
代表着将三维空间中的点投影到x-y平面上，也就是说，在每一条跟z轴平行的线上的点（
<strong><span class="math inline">\(x\)</span></strong> ）都对应着同样的
<strong><span class="math inline">\(b\)</span></strong> 。<br>
接下来给出一个稍微复杂一点的例子：<br> <img src="la-36.png" /><br>
怎么理解这个结果？首先这是一个<span
class="math inline">\(R^3\)</span>到<span
class="math inline">\(R^2\)</span>的投射，维度的损失带来的就是多对一的投射（在这个例子中，一条直线（由矩阵的零空间维度决定）投射到一个点）；其次，我们之前讨论过，
<strong><span class="math inline">\(Ax=b\)</span></strong> 的解可以视为
<strong><span class="math inline">\(Ax=0\)</span></strong>
解（零空间）的平移，在这个例子中， <strong><span
class="math inline">\(Ax=0\)</span></strong> 的解为一条直线（ <span
class="math inline">\(x=z\)</span> 与 <span
class="math inline">\(y=-z\)</span> 两个平面的交界线，图中紫色虚线），而
<strong><span class="math inline">\(Ax=b\)</span></strong>
的解即为其平移后的直线（紫色实线），绿色向量即为其平移的大小。<br>
其实也可以看出，如果一个矩阵的列数n多于行数m，这就意味着把一个高维空间的向量投影到一个低维空间（代数角度可以是矩阵没办法每一列都拥有主元，即列向量们线性依赖），这种情况下矩阵的零空间必然不只是零向量，进而
<strong><span class="math inline">\(Ax=b\)</span></strong>
的解也不只是一个向量，所以此时矩阵就无法实现一对一的投射。<br>
顺带一提，像最后这个例子，矩阵 <strong><span
class="math inline">\(A\)</span></strong>
的列空间（值域）与其取值空间一致（从代数角度其实就是，每一行都有主元，不然有的维度就被丢掉了），这种变换又叫onto变换（不知道怎么准确翻译...）。类似地，如果一个矩阵的列数n少于行数m，那么其取值空间维度（每一列向量含有的变量数目，即行数m）必然大于列空间（n个向量至多只能张成一个n维空间，<span
class="math inline">\(n&lt;m\)</span>）维度。<br>
对于一般的矩阵，上述两种变换，可以同时满足，也可以同时不满足，也可以只满足其中一个。但对于方阵而言，上述两种变换，必然同时满足，或同时不满足。为什么？对方阵而言，是否每一列都有主元（一对一变换成立）就意味着每一行都有主元（onto变换成立）？反之亦然。<br>
接下来讨论一个问题：矩阵变换与线性变换（Linear
Transformations）有什么关系？首先回忆下线性变换的定义，如果一个变换下面两个性质，则称其为线性变换：<br>
<span class="math display">\[
T(x+y)=T(x)+T(y),
T(cx)=cT(x)
\]</span>
显然，每一个矩阵变换都能满足上述性质，也就是说每一个矩阵变换背后都代表着线性变换；而反之，每一个线性变换也都可以用矩阵变换来表示。换句话说，矩阵变换与线性变换是完全等同的。（顺带一提，留意像
<span class="math inline">\(y=x+1\)</span>
这种两个变量之间虽然是线性关系，但其变换并不是线性变换，不要混淆线性关系与线性变换的概念。其实正是这个表达式中的常数项破坏了其线性变换。）<br>
也就是说，一个矩阵可以用下面的形式表示，其中<span
class="math inline">\(T\)</span>代表着某种线性变换，<strong><span
class="math inline">\(e_1, e_2, ..., e_n\)</span></strong> 代表着<span
class="math inline">\(R^n\)</span>的标准基向量。<br> <img
src="la-37.png" /><br> 怎么理解呢？矩阵 <strong><span
class="math inline">\(A\)</span></strong> 的每一列代表着对 <span
class="math inline">\(R^n\)</span>
空间中每一个维度进行的线性变换。有点抽象，举个例子好了：<br>
假如现在要构造一个矩阵，其代表着将<span
class="math inline">\(R^3\)</span>中的点关于xy平面进行对称映射，再将其投影到yz平面上，那么这个矩阵应该是什么？<br>
首先确定矩阵的第一列，也就是对<span
class="math inline">\(R^3\)</span>中的 <strong><span
class="math inline">\(e_1\)</span></strong>
进行操作，其在经过上述操作后，会落到零点，所以：<br> <img
src="la-38.png" /><br> 接着确定矩阵的第二列，也就是对<span
class="math inline">\(R^3\)</span>中的 <strong><span
class="math inline">\(e_2\)</span></strong>
进行操作，其在经过上述操作后，会保持不变，所以：<br> <img
src="la-39.png" /><br> 接着确定矩阵最后一列（变换后的空间仍是<span
class="math inline">\(R^3\)</span>），也就是对<span
class="math inline">\(R^3\)</span>中的 <strong><span
class="math inline">\(e_3\)</span></strong>
进行操作，其在经过上述操作后，其方向会取反，所以：<br> <img
src="la-40.png" /><br> 所以最后确定下来矩阵 <strong><span
class="math inline">\(A\)</span></strong> 应该为：<br> <img
src="la-41.png" /><br></p>
<h2 id="矩阵乘法matrix-multiplication">8. 矩阵乘法（Matrix
Multiplication）</h2>
<p>首先强调一下矩阵乘法（ <strong><span
class="math inline">\(AB\)</span></strong> ）中， 矩阵 <strong><span
class="math inline">\(B\)</span></strong> 的行数必须与矩阵 <strong><span
class="math inline">\(A\)</span></strong>
的列数一致。怎么理解呢？矩阵乘法可以理解为前一个矩阵 <strong><span
class="math inline">\(A\)</span></strong> 对后一个矩阵 <strong><span
class="math inline">\(B\)</span></strong>
的各列向量进行空间变换，如下所示：<br> <img src="la-42.png" /><br> 假设
<strong><span class="math inline">\(A\)</span></strong> 的维度为 <span
class="math inline">\(m\)</span> x <span
class="math inline">\(n\)</span>，那么其代表着一个从 <span
class="math inline">\(R^n\)</span> 到 <span
class="math inline">\(R^m\)</span> 的空间变换，那么必然 <strong><span
class="math inline">\(B\)</span></strong> 中列向量的维度也必须为 <span
class="math inline">\(n\)</span>，也就是矩阵 <strong><span
class="math inline">\(B\)</span></strong> 的行数必须为 <span
class="math inline">\(n\)</span>。<br> 同样重要的是，一个 <span
class="math inline">\(m\)</span> x <span
class="math inline">\(n\)</span> 的矩阵 <strong><span
class="math inline">\(A\)</span></strong> 乘上一个 <span
class="math inline">\(n\)</span> x <span
class="math inline">\(p\)</span> 的矩阵 <strong><span
class="math inline">\(B\)</span></strong>，其结果维度为 <span
class="math inline">\(m\)</span> x <span
class="math inline">\(p\)</span>。这个又怎么理解呢？同样还是矩阵乘法可以理解为前一个矩阵
<strong><span class="math inline">\(A\)</span></strong> 对后一个矩阵
<strong><span class="math inline">\(B\)</span></strong>
的各列向量进行空间变换，而前者代表着一个从 <span
class="math inline">\(R^n\)</span> 到 <span
class="math inline">\(R^m\)</span>
的空间变换，也就是变换后的列向量维度为 <span
class="math inline">\(m\)</span>，即 <strong><span
class="math inline">\(AB\)</span></strong> 结果的行数为 <span
class="math inline">\(m\)</span>；而原来矩阵 <strong><span
class="math inline">\(B\)</span></strong> 有 <span
class="math inline">\(p\)</span>
个列向量，对他们分别进行矩阵变换并不会改变他们的数量，也就是说，
<strong><span class="math inline">\(AB\)</span></strong> 结果的列数为
<span class="math inline">\(p\)</span>。<br>
类似地，基于矩阵乘法可以理解为前一个矩阵对后一个矩阵的各列向量进行空间变换，我们也可以理解矩阵乘法不满足交换律（对不同的向量进行不同的变换，他们相等的条件是不是很苛刻？），仅在少数情况下
<strong><span class="math inline">\(AB\)</span> = <span
class="math inline">\(BA\)</span></strong> （但当方阵 <strong><span
class="math inline">\(A\)</span></strong> 与 <strong><span
class="math inline">\(B\)</span></strong> 有 <strong><span
class="math inline">\(AB=I\)</span></strong> 时，直接会有 <strong><span
class="math inline">\(BA=I=AB\)</span></strong>）。<br>
而因为矩阵可以代表着多对一的变换，由 <strong><span
class="math inline">\(AB=AC\)</span></strong> 并不能得到 <strong><span
class="math inline">\(B=C\)</span></strong>，比如下面的例子：<br> <img
src="la-43.png" /><br>
上面是理解矩阵乘法的一个角度，也就是把第二个矩阵当成运算对象。而从另一个角度出发，之前我们提过，一个矩阵代表着一种线性变换，那么显然，两个矩阵相乘其实代表着做完一种线性变换之后接着再做另一种线性变换（链式线性变换）。<br></p>
<h2 id="矩阵的逆matrix-inverses">9. 矩阵的逆（Matrix Inverses）</h2>
<p>首先明确，我们只针对<strong>方阵</strong>去讨论可逆的性质（此章节的矩阵都特指方阵）。怎么判断矩阵是否可逆？一种方式是可以通过其行列式（determinant）是否为0来判断，为0时矩阵不可逆（后面再进一步讨论矩阵行列式）。另一种方式是将增广矩阵
<strong><span class="math inline">\((A|I_n)\)</span></strong> 变换为
<strong><span class="math inline">\((I_n|B)\)</span></strong>，那么矩阵
<strong><span class="math inline">\(B=A^{-1}\)</span></strong>，即
<strong><span class="math inline">\(B\)</span></strong> 为 <strong><span
class="math inline">\(A\)</span></strong> 的逆（这里隐含的条件是方阵
<strong><span class="math inline">\(A\)</span></strong> 必须满秩）。
而矩阵的逆是用来求解线性方程的一种很方便的方式（<strong><span
class="math inline">\(x=A^{-1}b\)</span></strong>）。<br>
以上都是一些代数角度的讨论，接下来我们进行一些更几何化的补充。前面我们说了，一个矩阵代表着一种线性变换，那么逆矩阵的作用就是“撤销”这个线性变换。这其实也很好理解，<strong><span
class="math inline">\(A^{-1}Ax=I_nx=x\)</span></strong>，首先
<strong><span class="math inline">\(A\)</span></strong> 对 <strong><span
class="math inline">\(x\)</span></strong> 进行了一个线性变换，然后
<strong><span class="math inline">\(A^{-1}\)</span></strong>
又撤销了这个变换（做了一个反向变换），结果就是 <strong><span
class="math inline">\(x\)</span></strong>
经过这两个线性变换之后仍是其自身。下面给几个例子：<br> 比如如果一个矩阵
<strong><span class="math inline">\(U\)</span></strong>
代表着缩小向量长度为<span
class="math inline">\(1/n\)</span>，那么其逆矩阵 <strong><span
class="math inline">\(T\)</span></strong> 就代表着放大向量长度至<span
class="math inline">\(n\)</span>倍：<br> <img src="la-44.png" /><br>
再比如一个矩阵 <strong><span class="math inline">\(T\)</span></strong>
代表着逆时针旋转45°，那么其逆矩阵 <strong><span
class="math inline">\(U\)</span></strong> 就代表着顺时针旋转45°：<br>
<img src="la-45.png" /><br>
那又如何理解矩阵不可逆呢？考虑下面这个例子：矩阵 <strong><span
class="math inline">\(A\)</span></strong>
代表着将三维空间中的点投影到xy平面，即: <br> <img src="la-35.png" /><br>
显然这里的矩阵 <strong><span class="math inline">\(A\)</span></strong>
并不满秩，也就是说它代表着一个多对一的变换，即在它对矩阵进行线性变换之后，我们就丢掉了在变换之前的信息（我们只能知道哪些点会投影到变换后的点上，但确定不了是哪个点），而上面我们说了，矩阵的逆代表着反向变换，但这个时候矩阵已经不知道应该反到哪个点上了，所以这个矩阵就不可逆了。也就是说，一个方阵只有代表着一对一变换（因为是方阵也代表着onto变换），其才可逆。<br></p>
<p>结合之前的内容回顾总结一下，一个 <span
class="math inline">\(n\)</span> x <span
class="math inline">\(n\)</span> 方阵 <strong><span
class="math inline">\(A\)</span></strong>
可逆，其与下列表述等价（它们之间也等价）：<br> 1. <strong><span
class="math inline">\(A\)</span></strong> 拥有 <span
class="math inline">\(n\)</span> 个主元；<br> 2. <strong><span
class="math inline">\(A\)</span></strong>
的简化列阶梯形矩阵（RREF）是单位矩阵 <strong><span
class="math inline">\(I_n\)</span></strong> ；<br> 3. <strong><span
class="math inline">\(A\)</span></strong> 的零空间只有{0}；<br> 4.
<strong><span class="math inline">\(A\)</span></strong> 的列空间是<span
class="math inline">\(R^n\)</span>；<br> 5. <strong><span
class="math inline">\(A\)</span></strong> 的列向量线性独立；<br> 6.
<strong><span class="math inline">\(A\)</span></strong>
的列向量可以张成<span class="math inline">\(R^n\)</span>；<br> 7.
<strong><span class="math inline">\(A\)</span></strong>
的列向量构成了<span class="math inline">\(R^n\)</span>的一组基；<br> 8.
<strong><span class="math inline">\(A\)</span></strong> 的秩是<span
class="math inline">\(n\)</span>（满秩）；<br> 9. <strong><span
class="math inline">\(Ax=b\)</span></strong> 对于每个<span
class="math inline">\(b\)</span>都只有唯一解（且在<span
class="math inline">\(R^n\)</span>中）；<br> 10. <strong><span
class="math inline">\(A\)</span></strong> 代表的变换为一对一变换；<br>
11. <strong><span class="math inline">\(A\)</span></strong>
代表的变换为onto变换。<br></p>
<p>也就是说，对一个可逆矩阵，上列表述都成立；而对于一个不可逆矩阵，上列表述都不成立。<br></p>
<p>顺带一提，要证明矩阵 <strong><span
class="math inline">\(A\)</span></strong> 可逆，只需要证明 <strong><span
class="math inline">\(AB=I_n\)</span></strong> 或 <strong><span
class="math inline">\(BA=I_n\)</span></strong>
中的一个就足够。这里给出一个不完全的证明帮助理解：<br> <strong><span
class="math inline">\(AB=I_n\)</span></strong> → <strong><span
class="math inline">\(A^{-1}AB=A^{-1}I_n\)</span></strong> →
<strong><span class="math inline">\(B=A^{-1}\)</span></strong> →
<strong><span class="math inline">\(BA = A^{-1}A\)</span></strong> →
<strong><span class="math inline">\(BA=I_n\)</span></strong></p>
<h2 id="行列式determinant">10. 行列式（Determinant）</h2>
<p>行列式是许多中文教材中非常吓人的一个概念，看起来定义很复杂，很多人又不知道它到底有什么作用，也就失去了学好它的欲望。但通过下面的讨论，我们应该会发现行列式其实是一个很重要也很有用的工具。<br></p>
<p>首先我们还是给出行列式很吓人的定义。行列式是一个将方阵转换为实数的函数（det:{square
matrices} → <span
class="math inline">\(R\)</span>），其满足下面四个性质：<br> 1. 对方阵
<strong><span class="math inline">\(A\)</span></strong> 进行行替换（row
replacement）操作并不会改变其行列式 det(<strong><span
class="math inline">\(A\)</span></strong>) 大小；<br> 2. 对方阵
<strong><span class="math inline">\(A\)</span></strong>
的某一行进行<span
class="math inline">\(c\)</span>倍缩放（scaling），其行列式也会缩放相应的倍数<span
class="math inline">\(c\)</span>；<br> 3. 对方阵 <strong><span
class="math inline">\(A\)</span></strong>
某两行进行交换（swapping），其行列式会取相反数；<br> 4. 单位矩阵
<strong><span class="math inline">\(I_n\)</span></strong>
的行列式等于1。<br></p>
<blockquote>
<p>引理：满足上述四个性质的将方阵转换为实数的函数有且仅有一个。进一步说，对于一个方阵，你都会得到一个唯一数值大小的行列式。</p>
</blockquote>
<p>为什么要给出这么一个复杂的定义，我们可以从两个角度进行理解：代数角度上方便我们对某方阵
<strong><span class="math inline">\(A\)</span></strong>
的行列式det(<strong><span
class="math inline">\(A\)</span></strong>)进行计算；几何上则更深刻告诉我们这么定义的动机。类似地，在本章节下方的讨论中，矩阵都特指方阵。<br></p>
<p>代数角度上，由于我们知道单位矩阵的行列式等于1，且满秩的方阵进行一系列的行变换都可以变成单位矩阵，而每一步的行变换对方阵的行列式的影响我们都知道，基于此我们可以很轻松得到一个满秩方阵的行列式。下面举一个例子：<br>
<img src="la-47.png" /><br>
首先我们知道最后一步的单位矩阵的行列式等于1，而其是由第四步的矩阵进行行替换操作（<span
class="math inline">\(R_1=R_1-4R_2\)</span>）得到的，而行替换操作前后的矩阵的行列式保持不变，所以此步操作之前的矩阵的行列式也等于1；而第三步是一个缩放操作（<span
class="math inline">\(R_2=R_2÷-7\)</span>）得到的，而对矩阵进行缩放同时也会导致其行列式大小的缩放，所以这一步操作之前的矩阵的行列式为<span
class="math inline">\(1×(-7)=-7\)</span>；以此类推（再考虑行交换操作会使矩阵的行列式取反），我们可以得到原始方阵的行列式为7。<br>
类似地，基于上述运算，我们能得到一个二维方阵的行列式的计算表达式如下：
<span class="math display">\[
\operatorname{det}\left(\begin{array}{ll}
a &amp; b \\
c &amp; d
\end{array}\right)=a d-b c
\]</span>
而对于一个阶梯形式方阵，其行列式就是其对角线上元素的乘积（对上/下三角方阵、对角阵都成立）。进一步的，只要一个方阵其某一行或某一列都为0，那么其行列式就为0。更进一步，非满秩的方阵其行列式为0。<br></p>
<p>记得在教科书中，我们学的行列式的计算方法是一种迭代的运算方式：拉普拉斯展开
/ 代数余子式展开（Laplace expansion / cofactor
expansion）。在这种计算方式下，我们可以按行展开：<br> <span
class="math display">\[
\operatorname{det}(A)=\sum_{j=1}^{n} a_{i j} C_{i j}=a_{i 1} C_{i
1}+a_{i 2} C_{i 2}+\cdots+a_{i n} C_{i n}
\]</span> 也可以按列展开：<br> <span class="math display">\[
\operatorname{det}(A)=\sum_{i=1}^{n} a_{i j} C_{i j}=a_{1 j} C_{1
j}+a_{2 j} C_{2 j}+\cdots+a_{n j} C_{n j}
\]</span> 其中，<span class="math inline">\(a_{ij}\)</span>是矩阵
<strong><span class="math inline">\(A\)</span></strong> 第<span
class="math inline">\(i\)</span>行第<span
class="math inline">\(j\)</span>列的元素，而<span
class="math inline">\(C_{ij}\)</span>是矩阵 <strong><span
class="math inline">\(A\)</span></strong> 第<span
class="math inline">\(i\)</span>行第<span
class="math inline">\(j\)</span>列的代数余子式（cofactor），其定义如下：<br>
<span class="math display">\[
C_{i j}=(-1)^{i+j} \operatorname{det}\left(A_{i j}\right)
\]</span> 其中<span class="math inline">\(A_{i j}\)</span>是矩阵
<strong><span class="math inline">\(A\)</span></strong> 删去第<span
class="math inline">\(i\)</span>行第<span
class="math inline">\(j\)</span>列后剩下的元素组成的维度为 <span
class="math inline">\((n-1) × (n-1)\)</span> 的矩阵。<br>
顺带一提的是，上述第一种运算的计算复杂度也相对较低，不管对人还是对机器而言（<span
class="math inline">\(O(n^3)\)</span>），而代数余子式展开计算的计算复杂度为<span
class="math inline">\(O(n !) \approx O\left(n^{n}
\sqrt{n}\right)\)</span>。那数学家为什么还要开发代数余子式展开这么一套工具，它在什么时候有用呢？第一种情况，如果一个矩阵的某行/列中有很多的零，那么其对应位置的代数余子式就没有计算的意义了，在这种情况下计算可以很大程度被简化；另一种情况，如果一个矩阵里有未知大小的元素，这个时候用上述第一种运算是不太合适的，因为我们并不确定这个未知元素在矩阵约简成阶梯矩阵后是否会是主元。<br></p>
<p>而在几何角度上，矩阵的行列式与“容积”（volume）大小有着密不可分的关系。行列式计算着平行六面体（paralellepiped）的容积
，其由 <strong><span class="math inline">\(R^n\)</span></strong>
中的<span class="math inline">\(n\)</span>个向量 <span
class="math inline">\(v_1, v_2, ..., v_n\)</span>确定，当<span
class="math inline">\(n=2\)</span>时，其退化为一个平行四边形。下面举几个例子：<br>
首先二维与三维空间中的标准正交基组成的平行四边形/平行六面体如下图所示：<br>
<img src="la-49.png" /><br>
而对于二维与三维空间中的线性独立的任意二/三个向量组成的平行四边形/平行六面体举例如下图所示：<br>
<img src="la-50.png" /><br>
那么如果上述组成平行四边形/平行六面体的向量线性依赖呢？这时几何图形的“容积”为0，如下图所示：<br>
<img src="la-51.png" /><br>
这些向量线性依赖，则意味着它们组成的矩阵非满秩，而我们上面已经讨论过，非满秩的矩阵的行列式为0，所以这边我们就得到一个很重要的观察：几个向量组成的平行六面体（包含二维空间下的平行四边形，下面不再赘述）的容积为0，当且仅当它们组成的矩阵（作为行向量或列向量）的行列式为0。更进一步地，其实上述平行六面体（记为P）的容积与上述矩阵的行列式（记为
<strong><span
class="math inline">\(A\)</span></strong>）绝对值一直相等：<br> <span
class="math display">\[
|\operatorname{det}(A)|=\operatorname{vol}(P)
\]</span> 直觉上怎么理解呢？回顾行列式的定义，我们有：<br> 1. 对方阵
<strong><span class="math inline">\(A\)</span></strong> 进行行替换（row
replacement）操作并不会改变 |det(<strong><span
class="math inline">\(A\)</span></strong>)| 大小；<br> 2. 对方阵
<strong><span class="math inline">\(A\)</span></strong>
的某一行进行<span
class="math inline">\(c\)</span>倍缩放（scaling），其行列式的绝对值也会缩放相应的倍数|<span
class="math inline">\(c\)</span>|；<br> 3. 对方阵 <strong><span
class="math inline">\(A\)</span></strong>
某两行进行交换（swapping），其行列式绝对值保持不变；<br> 4. 单位矩阵
<strong><span class="math inline">\(I_n\)</span></strong>
的行列式等于1。<br>
而平行六面体的容积如何计算？底（base）×高（height），如下图所示：<br>
<img src="la-52.png" /><br> 首先，我们考虑对方阵 <strong><span
class="math inline">\(A\)</span></strong> 进行行替换（row
replacement）操作对其对应的平行六面体容积的影响：<br> <img
src="la-53.png" /><br>
可以发现，行替换操作并不会改变平行六面体的底或高，进而其容积也不会改变。也就是说，一组向量的行替换操作既不会改变其组成的平行六面体的容积，也不会改变其组成的方阵
<strong><span class="math inline">\(A\)</span></strong>
行列式绝对值的大小。<br> 其次，我们考虑对方阵 <strong><span
class="math inline">\(A\)</span></strong> 的某一行进行<span
class="math inline">\(c\)</span>倍缩放（scaling）操作对其对应的平行六面体容积的影响：<br>
<img src="la-54.png" /><br>
可以发现，缩放操作会使平行六面体的高也进行相应的缩放，进而其容积也进行相应的缩放。也就是说，对方阵
<strong><span class="math inline">\(A\)</span></strong>
的某一行进行<span
class="math inline">\(c\)</span>倍缩放（scaling），其行列式的绝对值和对应的平行六面体的容积也会缩放相应的倍数|<span
class="math inline">\(c\)</span>|。<br> 再者，我们考虑对方阵
<strong><span class="math inline">\(A\)</span></strong>
进行行交换（swapping）操作对其对应的平行六面体容积的影响：<br> <img
src="la-55.png" /><br>
显然，除了对应方阵行列式的绝对值，行交换操作也不会改变平行六面体容积的大小。<br>
最后，同样显然的是，单位矩阵内的向量组成的平行六面体的容积也为1。<br></p>
<p>现在我们已经知道了一个方阵的行列式绝对值等于其内在向量组成的平行六面体的容积，那进一步我们有没有可能摆脱掉这个烦人的绝对值呢？答案当然是有的，只要我们引入有符号的容积（signed
volume，可正可负的容积，就像在微积分中那样有负的面积）。那这个容积的正负性与对应方阵行列式的正负性关系是什么？<br>
1.
对于一个二维方阵，行列式的正负性告诉我们组成它的向量的方向关系。如果行列式为正，则意味着第二个向量在第一个向量的逆时针方向上（角度小于180°，下同）；反之，则在顺时针方向上，如下图所示：<br>
<img src="la-56.png" /><br> 2.
对于一个三维方阵，行列式的正负性则由右手定则（right-hand
rule）决定。如果你把食指（index finger）指向第一个向量，中指（middle
finger）指向第二个向量，则如果你的拇指（thumb）大致可以指向第三个向量，那么行列式为正；而如果你的拇指大致指向第三个向量的反方向，那么行列式为负，如下图所示：<br>
<img src="la-57.png" /><br> 3.
我们已经看到行列式的正负性与有符号容积的正负性有很大的关系，所以在更高维度中，有符号容积的正负性经常由行列式的正负性定义。</p>
<p>回顾我们之前讨论过的，一个矩阵本身代表着一个线性变换。那么其行列式对这个变换有什么意义呢？这里有一个定理：<strong><span
class="math inline">\(A\)</span></strong> 是一个<span
class="math inline">\(n × n\)</span>的方阵，而<span
class="math inline">\(T\)</span>代表着其对应的线性变换（<span
class="math inline">\(T(x)=\mathbf{A}x\)</span>，<span
class="math inline">\(\mathbf{R^n} → \mathbf{R^n}\)</span>），而S是<span
class="math inline">\(\mathbf{R^n}\)</span>中的一个区域，则有（证明参见参考书籍4.3）：<br>
<span class="math display">\[
\operatorname{vol}(T(S))=|\operatorname{det}(A)| \cdot
\operatorname{vol}(S)
\]</span>
这边举一个有趣的例子：用行列式来求解椭圆的面积。我们要求解的椭圆方程为：<br>
<span class="math display">\[
\left(\frac{2 x-y}{2}\right)^{2}+\left(\frac{y+3 x}{3}\right)^{2}=1
\]</span> 它与单位圆（<span
class="math inline">\(X^2+Y^2=1\)</span>）存在下面的变换关系：<br> <span
class="math display">\[
\begin{array}{l}
X=\frac{2 x-y}{2} \\
Y=\frac{y+3 x}{3}
\end{array}
\]</span> 也就是说，我们可以定义一个线性变换<span
class="math inline">\(T\)</span>，在经过这个线性变换之后，原本在椭圆上的点会变换到单位圆上：<br>
<span class="math display">\[
T\left(\begin{array}{l}
x \\
y
\end{array}\right)=\left(\begin{array}{l}
(2 x-y) / 2 \\
(y+3 x) / 3
\end{array}\right)
\]</span> 也就是如下图所示：<br> <img src="la-58.png" /><br>
而单位圆的面积和线性变换矩阵的行列式我们都易求，再根据上面的公式，我们可以轻易求得椭圆的面积：<br>
<span class="math display">\[
\pi=\operatorname{vol}(C)=\operatorname{vol}(T(E))=|\operatorname{det}(A)|
\cdot \operatorname{vol}(E)=\frac{5}{6} \operatorname{vol}(E)
\]</span> 所以椭圆的面积为<span class="math inline">\(6
\pi/5\)</span>。</p>
<p>上面讲完了怎么定义并理解行列式这个概念，那么它到底有什么用呢？<br>
首先考虑行列式与方阵可逆性的关系我们有，当且仅当一个方阵的行列式不为零时，其可逆。通过在章节9中的分析我们知道，一个方阵不可逆，那么其不满秩，也就是其约简到阶梯式后至少会有一行全为0，那么其行列式就为0。将之前对矩阵可逆条件的讨论结合到一起，我们有下述表述都等价
(<strong><span class="math inline">\(A\)</span></strong> 为方阵)：<br>
1. <strong><span class="math inline">\(A\)</span></strong> 拥有 <span
class="math inline">\(n\)</span> 个主元；<br> 2. <strong><span
class="math inline">\(A\)</span></strong>
的简化列阶梯形矩阵（RREF）是单位矩阵 <strong><span
class="math inline">\(I_n\)</span></strong> ；<br> 3. <strong><span
class="math inline">\(A\)</span></strong> 的零空间只有{0}；<br> 4.
<strong><span class="math inline">\(A\)</span></strong> 的列空间是<span
class="math inline">\(R^n\)</span>；<br> 5. <strong><span
class="math inline">\(A\)</span></strong> 的列向量线性独立；<br> 6.
<strong><span class="math inline">\(A\)</span></strong>
的列向量可以张成<span class="math inline">\(R^n\)</span>；<br> 7.
<strong><span class="math inline">\(A\)</span></strong>
的列向量构成了<span class="math inline">\(R^n\)</span>的一组基；<br> 8.
<strong><span class="math inline">\(A\)</span></strong> 的秩是<span
class="math inline">\(n\)</span>（满秩）；<br> 9. <strong><span
class="math inline">\(Ax=b\)</span></strong> 对于每个<span
class="math inline">\(b\)</span>都只有唯一解（且在<span
class="math inline">\(R^n\)</span>中）；<br> 10. <strong><span
class="math inline">\(A\)</span></strong> 代表的变换为一对一变换；<br>
11. <strong><span class="math inline">\(A\)</span></strong>
代表的变换为onto变换；<br> 12. <strong><span
class="math inline">\(A\)</span></strong> 可逆；<br> 13. <strong><span
class="math inline">\(A\)</span></strong> 的行列式不为零。<br></p>
<p>再者方阵行/列向量线性独立性与其行列式的关系我们有，当一个方阵的行或列向量线性依赖，那么其行列式为0。如果其行向量线性依赖，则意味着我们可以通过行操作得到一个全为零的行，而有全为0的行的方阵的行列式为0，进而又可以得到原始方阵行列式为0；而如果其列向量线性依赖，则由上述等价条件可以直接得到其行列式为0。比如下列的几个方阵的行列式都为0：<br>
<img src="la-48.png" /><br></p>
<p>同时行列式也满足可乘性，即： <span class="math display">\[
\operatorname{det}(A B)=\operatorname{det}(A) \operatorname{det}(B)
\]</span> 其中 <strong><span class="math inline">\(A\)</span></strong>
与 <strong><span class="math inline">\(B\)</span></strong>
都为方阵。这个性质可以由上述的行列式唯一性引理证明，详细证明可参见参考书籍。而由这个性质，我们又可以得到，对于方阵
<strong><span class="math inline">\(A\)</span></strong>， 在<span
class="math inline">\(n≥1\)</span>条件下有：<br> <span
class="math display">\[
\operatorname{det}\left(A^{n}\right)=\operatorname{det}(A)^{n}
\]</span> 而如果方阵 <strong><span
class="math inline">\(A\)</span></strong> 可逆，上式在<span
class="math inline">\(n≤0\)</span>时也成立，特别地，我们有：<br> <span
class="math display">\[
\operatorname{det}\left(A^{-1}\right)=\frac{1}{\operatorname{det}(A)}
\]</span></p>
<p>此外，一个方阵 <strong><span
class="math inline">\(A\)</span></strong> 转置后的行列式保持不变：<br>
<span class="math display">\[
\operatorname{det}(A)=\operatorname{det}\left(A^{T}\right)
\]</span> 由这个性质，我们又可以引申到：<br> 1. 对方阵 <strong><span
class="math inline">\(A\)</span></strong> 进行列替换（column
replacement）操作并不会改变其行列式 det(<strong><span
class="math inline">\(A\)</span></strong>) 大小；<br> 2. 对方阵
<strong><span class="math inline">\(A\)</span></strong>
的某一列进行<span
class="math inline">\(c\)</span>倍缩放（scaling），其行列式也会缩放相应的倍数<span
class="math inline">\(c\)</span>；<br> 3. 对方阵 <strong><span
class="math inline">\(A\)</span></strong>
某两列进行交换（swapping），其行列式会取相反数。<br></p>
<p>这就意味着，我们要求解一个方阵的行列式时，行列的操作是等价的。<br></p>
<h2 id="特征值与特征向量eigenvalues-and-eigenvectors">10.
特征值与特征向量（Eigenvalues and Eigenvectors）</h2>
<p>特征值与特征向量在解决许多现实问题的应用中都扮演了举足轻重的角色，但怎么理解它们？它们为什么重要？他们又有什么用？这是我们接下来尝试解答的问题。<br></p>
<p>首先让我们回忆一下特征值与特征向量的定义(非常重要！)。对于下式：
<span class="math display">\[
Av=\lambda v
\]</span> 其中<span
class="math inline">\(A\)</span>为<strong>方阵</strong>（只对方阵考虑特征值与特征向量，下述矩阵表述均指方阵），<span
class="math inline">\(v\)</span>为向量，<span
class="math inline">\(\lambda\)</span>为标量。如果其有非平凡（非零）解<span
class="math inline">\(v\)</span>，那么我们称<span
class="math inline">\(\lambda\)</span>是特征向量<span
class="math inline">\(v\)</span>对应的特征值。特征值与特征向量就是在描述矩阵<span
class="math inline">\(A\)</span>的特征。一个矩阵可以有多个特征值/特征向量，但每个特征值与特征向量一一对应。如果接受<span
class="math inline">\(v\)</span>为零向量作为特征向量，那么其将有无数个对应的特征值，这并不合适；但特征值为0是可能的，比如下面这个例子：
<span class="math display">\[
A v=\left(\begin{array}{ll}
1 &amp; 3 \\
2 &amp; 6
\end{array}\right)\left(\begin{array}{c}
-3 \\
1
\end{array}\right)=\left(\begin{array}{l}
0 \\
0
\end{array}\right)=0 v
\]</span></p>
<p>几何上来看，上面的定义告诉我们，<span
class="math inline">\(Av\)</span>、<span class="math inline">\(\lambda
v\)</span>与原点共线。也就是说，矩阵<span
class="math inline">\(A\)</span>对其特征向量<span
class="math inline">\(v\)</span>进行线性变换后，得到<span
class="math inline">\(\lambda v\)</span>，<span
class="math inline">\(v\)</span>与<span class="math inline">\(\lambda
v\)</span>仅仅相差一个缩放因子<span
class="math inline">\(\lambda\)</span>（标量，即其对应特征值），如下图所示：<br></p>
<p><img src="la-59.png" /><br></p>
<p>图中<span class="math inline">\(v\)</span>为矩阵<span
class="math inline">\(A\)</span>的特征向量，而<span
class="math inline">\(w\)</span>不是。<br></p>
<p>此外，矩阵的特征向量有一个很重要的性质：对应不同特征值的特征向量线性独立。一个证明思路是反证法。具体可参见参考书籍5.1。</p>
<p>上面我们讨论了怎么判断一个给定的向量<span
class="math inline">\(v\)</span>是否是方阵<span
class="math inline">\(A\)</span>的特征向量，接着反过来，我们讨论怎么判断一个给定的数值<span
class="math inline">\(\lambda\)</span>是否是方阵<span
class="math inline">\(A\)</span>的特征值，且是的话求其对应的特征向量。对于特征值、特征向量的定义式，我们有：
<span class="math display">\[
A v=\lambda v \Longleftrightarrow \left(A-\lambda I_{n}\right) v=0
\]</span> 也就是说，如果上式存在非平凡解，或者说零空间Null(<span
class="math inline">\(A-\lambda
I_n\)</span>)中存在非零向量，那么这些非零解就是矩阵<span
class="math inline">\(A\)</span>的特征向量；而如果上式不存在非平凡解，则<span
class="math inline">\(\lambda\)</span>不是<span
class="math inline">\(A\)</span>的特征值。上述的零空间（Null(<span
class="math inline">\(A-\lambda I_n\)</span>)）即为方阵<span
class="math inline">\(A\)</span>的 <strong><span
class="math inline">\(\lambda\)</span>-特征空间（Eigenspace）</strong>，注意其中也包含了零向量，但零向量不是矩阵<span
class="math inline">\(A\)</span>的特征向量。进一步我们有推论：一个<span
class="math inline">\(n\times n\)</span>矩阵<span
class="math inline">\(A\)</span>至多拥有<span
class="math inline">\(n\)</span>个特征值，因为在上述特征空间中至多有<span
class="math inline">\(n\)</span>个线性独立的非零向量（即特征向量）。但这里也要注意的是，一个特征向量仅对应一个特征值，但一个特征值对应多个与原点共线的特征向量（比如，<span
class="math inline">\(v_1\)</span>是矩阵<span
class="math inline">\(A\)</span>的特征向量，则<span
class="math inline">\(cv_1\)</span>也是矩阵<span
class="math inline">\(A\)</span>的特征向量，且它们对应的特征值相同），因为在特征空间中一个非零子空间（即特征向量所在的子空间）是无限大的。另外，与之前对零空间的讨论联系起来，一个<span
class="math inline">\(A\)</span>的特征值对应的特征向量的数量为方程<span
class="math inline">\((A-\lambda I_{n})
v=0\)</span>化简为阶梯式后的自由变量的数量。下面举一个实例：<br> <span
class="math display">\[
A_1=
\left[\begin{array}{ccc}
3.50 &amp; 0.00 &amp; 3.00 \\
-1.50 &amp; 2.00 &amp; -3.00 \\
-1.50 &amp; 0.00 &amp; -1.00
\end{array}\right]
\]</span> 它有两个特征值：<span
class="math inline">\(\lambda_1=0.5\)</span>与<span
class="math inline">\(\lambda_2=2\)</span>。<span
class="math inline">\(\lambda_1\)</span>-特征空间为下图中的绿色一维空间（一个特征向量），而<span
class="math inline">\(\lambda_2\)</span>-特征空间为下图中的紫色二维空间（两个特征向量）。<br>
<img src="la-60.png" /><br></p>
<p>而如果考虑0-特征空间，其即为Null(<span
class="math inline">\(A\)</span>)，这时当且仅当Null(<span
class="math inline">\(A\)</span>)不只是{0}，0是矩阵<span
class="math inline">\(A\)</span>的特征值，也就是说需要矩阵<span
class="math inline">\(A\)</span>不可逆。回顾之前的可逆矩阵定理，现在我们又可以添加一条等价地表述（14）：
1. <strong><span class="math inline">\(A\)</span></strong> 拥有 <span
class="math inline">\(n\)</span> 个主元；<br> 2. <strong><span
class="math inline">\(A\)</span></strong>
的简化列阶梯形矩阵（RREF）是单位矩阵 <strong><span
class="math inline">\(I_n\)</span></strong> ；<br> 3. <strong><span
class="math inline">\(A\)</span></strong> 的零空间只有{0}；<br> 4.
<strong><span class="math inline">\(A\)</span></strong> 的列空间是<span
class="math inline">\(R^n\)</span>；<br> 5. <strong><span
class="math inline">\(A\)</span></strong> 的列向量线性独立；<br> 6.
<strong><span class="math inline">\(A\)</span></strong>
的列向量可以张成<span class="math inline">\(R^n\)</span>；<br> 7.
<strong><span class="math inline">\(A\)</span></strong>
的列向量构成了<span class="math inline">\(R^n\)</span>的一组基；<br> 8.
<strong><span class="math inline">\(A\)</span></strong> 的秩是<span
class="math inline">\(n\)</span>（满秩）；<br> 9. <strong><span
class="math inline">\(Ax=b\)</span></strong> 对于每个<span
class="math inline">\(b\)</span>都只有唯一解（且在<span
class="math inline">\(R^n\)</span>中）；<br> 10. <strong><span
class="math inline">\(A\)</span></strong> 代表的变换为一对一变换；<br>
11. <strong><span class="math inline">\(A\)</span></strong>
代表的变换为onto变换；<br> 12. <strong><span
class="math inline">\(A\)</span></strong> 可逆；<br> 13. <strong><span
class="math inline">\(A\)</span></strong> 的行列式不为零；<br> 14.
0不是矩阵 <strong><span class="math inline">\(A\)</span></strong>
的特征值。<br></p>
<p>接下来，我们要考虑的就是怎么直接求解一个矩阵的特征值了，这里我们要用到的一个工具是<strong>特征多项式（Characteristic
Polynomial）</strong>。对于<span class="math inline">\(n \times
n\)</span>方阵<span
class="math inline">\(A\)</span>，其特征多项式定义为： <span
class="math display">\[
f(\lambda)=\operatorname{det}\left(A-\lambda I_{n}\right)
\]</span> 举个例子，对于矩阵<span
class="math inline">\(A=\left(\begin{array}{ccc} 0 &amp; 6 &amp; 8 \\
\frac{1}{2} &amp; 0 &amp; 0 \\ 0 &amp; \frac{1}{2} &amp; 0
\end{array}\right)\)</span>，我们求其特征多项式： <span
class="math display">\[
\begin{aligned}
f(\lambda)=\operatorname{det}\left(A-\lambda I_3\right)
&amp;=\operatorname{det}\left(\begin{array}{ccc}
-\lambda &amp; 6 &amp; 8 \\
\frac{1}{2} &amp; -\lambda &amp; 0 \\
0 &amp; \frac{1}{2} &amp; -\lambda
\end{array}\right) \\
&amp;=8\left(\frac{1}{4}-0 \cdot-\lambda\right)-\lambda\left(\lambda^2-6
\cdot \frac{1}{2}\right) \\
&amp;=-\lambda^3+3 \lambda+2 .
\end{aligned}
\]</span>
可以看出，特征多项式是一个以特征值为自变量的多项式。它有什么用呢？这边我们有一个很漂亮的定理：特征多项式的根就是对应矩阵的特征值（具体证明可参见参考书籍5.2）。也就是说：
<span class="math display">\[
\lambda_0 \text { is an eigenvalue of } A \Longleftrightarrow
f(\lambda_0)=0
\]</span> 对于上面的矩阵<span
class="math inline">\(A\)</span>，我们就可以按照这个定理求得其特征值：
<span class="math display">\[
f(\lambda)=-\lambda^3+3 \lambda+2=-(\lambda-2)(\lambda+1)^2
\]</span> 所以矩阵<span class="math inline">\(A\)</span>的特征值为<span
class="math inline">\(2,-1\)</span>。接着我们依据之前的求特定特征值对应特征向量的方法，可以得到其特征向量：
<span class="math display">\[
A-2 I_3=\left(\begin{array}{ccc}
-2 &amp; 6 &amp; 8 \\
\frac{1}{2} &amp; -2 &amp; 0 \\
0 &amp; \frac{1}{2} &amp; -2
\end{array}\right) \quad
\stackrel{\mathrm{RREF}}{\longrightarrow}\left(\begin{array}{ccc}
1 &amp; 0 &amp; -16 \\
0 &amp; 1 &amp; -4 \\
0 &amp; 0 &amp; 0
\end{array}\right)
\]</span> 即： <span class="math display">\[
\left\{\begin{array}{l}
x=16 z \\
y=4 z \\
z=z
\end{array} \longrightarrow\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)=z\left(\begin{array}{c}
16 \\
4 \\
1
\end{array}\right) .\right.
\]</span> 所以<span class="math inline">\(A\)</span>的2-特征空间为：
<span class="math display">\[
\operatorname{Span}\left\{\left(\begin{array}{c}
16 \\
4 \\
1
\end{array}\right)\right\}
\]</span> 类似地，我们可以得到<span
class="math inline">\(A\)</span>的-1-特征空间为： <span
class="math display">\[
\operatorname{Span}\left\{\left(\begin{array}{c}
4 \\
-2 \\
1
\end{array}\right)\right\}
\]</span> 至此，我们已经有能力去求某个矩阵的特征值与特征向量了。<br></p>
<p>接下来，我们考虑一种特殊情况——对角阵。这时候求解特征值非常简单，一个对角阵的特征值即为其对角线上的元素。比如对于矩阵<span
class="math inline">\(A=\left(\begin{array}{cccc} 1 &amp; 7 &amp; 2
&amp; 4 \\ 0 &amp; 1 &amp; 3 &amp; 11 \\ 0 &amp; 0 &amp; \pi &amp; 101
\\ 0 &amp; 0 &amp; 0 &amp; 0
\end{array}\right)\)</span>，其特征值即为<span class="math inline">\(1,
\pi, 0\)</span>。<br></p>
<p>在一开始介绍特征值特征向量的时候我们说它很重要，那它到底有什么用？接下来我们要尝试回答这个问题。首先我们先介绍
<strong>相似矩阵（Similar Matrices）</strong> 的概念：如果存在一个<span
class="math inline">\(n \times n\)</span> <strong>可逆</strong>矩阵<span
class="math inline">\(C\)</span>使得： <span class="math display">\[
A=CBC^{-1}
\]</span> 那么就称<span class="math inline">\(n \times
n\)</span>矩阵<span class="math inline">\(A\)</span>、<span
class="math inline">\(B\)</span>为相似矩阵。相似矩阵具有自反性（Reflexivity，矩阵与其自身相似）、对称性（Symmetry，矩阵<span
class="math inline">\(A\)</span>与<span
class="math inline">\(B\)</span>相似即矩阵<span
class="math inline">\(B\)</span>与<span
class="math inline">\(A\)</span>相似）与传递性（Transitivity，矩阵<span
class="math inline">\(A\)</span>与<span
class="math inline">\(B\)</span>相似，矩阵<span
class="math inline">\(B\)</span>与<span
class="math inline">\(C\)</span>相似，即矩阵<span
class="math inline">\(A\)</span>与<span
class="math inline">\(C\)</span>相似）。<br></p>
<p>为何相似矩阵重要？在下面的讨论中，我们可以看到，从几何上看，相似矩阵在<strong>不同的坐标系</strong>下执行<strong>相同的操作</strong>。为什么我们要求定义中的<span
class="math inline">\(n \times n\)</span>矩阵<span
class="math inline">\(C\)</span>可逆？回顾我们之前的矩阵可逆定理，我们有<span
class="math inline">\(C\)</span>中各列可作为基张成<span
class="math inline">\(R^n\)</span>空间。也就是说我们有： <span
class="math display">\[
C[x]_{\mathcal{B}} = I_n x = x \quad \text { and } \quad C^{-1}
x=[x]_{\mathcal{B}}
\]</span> 其中<span
class="math inline">\(x\)</span>表示一个向量在标准正交基（也就是乘上单位矩阵<span
class="math inline">\(I_n\)</span>）下的坐标，而<span
class="math inline">\([x]_{\mathcal{B}}\)</span>则表示以<span
class="math inline">\(C\)</span>中各列为基的空间（<span
class="math inline">\(\mathcal{B}\)</span>-坐标系）中该向量的坐标。换句话说，<span
class="math inline">\(C\)</span>将<span
class="math inline">\(\mathcal{B}\)</span>-坐标系下的坐标变换为了标准正交坐标系下的坐标，而<span
class="math inline">\(C^{-1}\)</span>把标准正交坐标系下的坐标变换为了<span
class="math inline">\(\mathcal{B}\)</span>-坐标系下的坐标。基于这样的理解，对于相似矩阵<span
class="math inline">\(A\)</span>、<span
class="math inline">\(B\)</span>： <span class="math display">\[
y = Ax = CBC^{-1}x = C(B(C^{-1}x))
\]</span> 我们先计算<span
class="math inline">\(C^{-1}x\)</span>，也就是将标准正交坐标系下的坐标变换为了<span
class="math inline">\(\mathcal{B}\)</span>-坐标系下的坐标；接着对运算结果乘上<span
class="math inline">\(B\)</span>，也就是在<span
class="math inline">\(\mathcal{B}\)</span>-坐标系下进行矩阵运算；最后再在结果上乘上<span
class="math inline">\(C\)</span>，将运算结果坐标转换为标准正交坐标系下的坐标。如图所示：<br>
<img src="la-61.png" /><br> 总结而言，<span
class="math inline">\(B\)</span>在<span
class="math inline">\(\mathcal{B}\)</span>-坐标系下进行与<span
class="math inline">\(A\)</span>在标准正交坐标系下相同的矩阵变换。下面给一个具体的简单例子。对于：
<span class="math display">\[
A=\left(\begin{array}{cc}
1 / 2 &amp; 3 / 2 \\
3 / 2 &amp; 1 / 2
\end{array}\right) \quad B=\left(\begin{array}{cc}
2 &amp; 0 \\
0 &amp; -1
\end{array}\right) \quad C=\left(\begin{array}{cc}
1 &amp; 1 \\
1 &amp; -1
\end{array}\right)
\]</span> 我们有<span class="math inline">\(A =
CBC^{-1}\)</span>。首先矩阵<span
class="math inline">\(B\)</span>是一个对角阵，其执行的操作很简单，对第一个维度方向的坐标放大两倍，对第二个维度方向的坐标取反，如图所示:<br>
<img src="la-62.png" /><br> 下图中我们以标准正交坐标系下<span
class="math inline">\(x=\left(\begin{array}{c} 0 \\ -2
\end{array}\right)\)</span>为例（右图绿色），先对其乘上<span
class="math inline">\(C^{-1}\)</span>得到<span
class="math inline">\(\mathcal{B}\)</span>下的坐标<span
class="math inline">\([x]_{\mathcal{B}}=\left(\begin{array}{c} -1 \\ 1
\end{array}\right)\)</span>（左图绿色），接着对 <span
class="math inline">\([x]_\mathcal{B}\)</span>
执行矩阵变换，即横坐标放大两倍，纵坐标取反，得到 <span
class="math inline">\(B[x]_\mathcal{B}\)</span>（左图红色），最后再对其乘上<span
class="math inline">\(C\)</span>，得到标准正交坐标系下的<span
class="math inline">\(Ax\)</span>（右图红色）。<br></p>
<p>而对于相似矩阵，它们的特征值相同、迹（trace）相同、行列式相同（证明可见参考书籍5.3）。一个方阵的迹是其对角线上各元素的累计和：
<span class="math display">\[
\operatorname{Tr}\left(\begin{array}{ccccc}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1, n-1} &amp; a_{1 n} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2, n-1} &amp; a_{2 n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
a_{n-1,1} &amp; a_{n-1,2} &amp; \cdots &amp; a_{n-1, n-1} &amp; a_{n-1,
n} \\
a_{n 1} &amp; a_{n 2} &amp; \cdots &amp; a_{n, n-1} &amp; a_{n n}
\end{array}\right)=a_{11}+a_{22}+\cdots+a_{n n} .
\]</span> 而相似矩阵的特征向量之间相差着一个矩阵变换：对于<span
class="math inline">\(A=CBC^{-1}\)</span>，如果<span
class="math inline">\(v\)</span>是<span
class="math inline">\(A\)</span>的一个特征向量则<span
class="math inline">\(C^{-1}v\)</span>是<span
class="math inline">\(B\)</span>的一个特征向量，如果<span
class="math inline">\(v\)</span>是<span
class="math inline">\(B\)</span>的一个特征向量则<span
class="math inline">\(Cv\)</span>为<span
class="math inline">\(A\)</span>的一个特征向量。或者说，对于<span
class="math inline">\(A=CBC^{-1}\)</span>，<span
class="math inline">\(C^{-1}\)</span>把矩阵<span
class="math inline">\(A\)</span>的<span
class="math inline">\(\lambda\)</span>-特征空间变换到<span
class="math inline">\(B\)</span>的<span
class="math inline">\(\lambda\)</span>-特征空间；而<span
class="math inline">\(C\)</span>把矩阵<span
class="math inline">\(B\)</span>的<span
class="math inline">\(\lambda\)</span>-特征空间变换到<span
class="math inline">\(A\)</span>的<span
class="math inline">\(\lambda\)</span>-特征空间。</p>
从上面的例子中，我们可以看到，如果一个矩阵与一个对角阵相似，那么我们就可以比较轻易理解它的空间变换行为。对于这样有趣的矩阵，我们给他一个名字：<strong>可对角化矩阵（diagonalizable
matrix）</strong>。很自然地，接下来我们就想问，怎么判断一个矩阵是否可对角化？这里我们就引入对角化定理（Diagonalization
Theorem）（证明见参考书籍5.4）：当且仅当<span class="math inline">\(n
\times n\)</span>矩阵<span class="math inline">\(A\)</span>有<span
class="math inline">\(n\)</span>个线性独立特征向量时，其可对角化，即对于<span
class="math inline">\(A=CDC^{-1}\)</span>有： <span
class="math display">\[
C=\left(\begin{array}{cccc}
\mid &amp; \mid &amp; &amp; \mid \\
v_{1} &amp; v_{2} &amp; \cdots &amp; v_{n} \\
\mid &amp; \mid &amp; &amp; \mid
\end{array}\right) \quad D=\left(\begin{array}{cccc}
\lambda_{1} &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \lambda_{2} &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_{n}
\end{array}\right)
\]</span> 其中<span class="math inline">\(v_i\)</span>为<span
class="math inline">\(A\)</span>线性独立的特征向量，而<span
class="math inline">\(\lambda_i\)</span>为各特征向量对应的特征值，<span
class="math inline">\(i \in [1, n]\)</span>。特别地，对于一个<span
class="math inline">\(n \times n\)</span>的矩阵，如果它有<span
class="math inline">\(n\)</span>个不相等的特征值，则其可对角化；但矩阵可对角化，其不一定有<span
class="math inline">\(n\)</span>个不相等的特征值。留意到对角化并不唯一，只要对应好特征向量与特征值的位置关系：
<span class="math display">\[
\begin{aligned}
A &amp;=\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
v_{1} &amp; v_{2} &amp; v_{3} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)\left(\begin{array}{ccc}
\lambda_{1} &amp; 0 &amp; 0 \\
0 &amp; \lambda_{2} &amp; 0 \\
0 &amp; 0 &amp; \lambda_{3}
\end{array}\right)\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
v_{1} &amp; v_{2} &amp; v_{3} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)^{-1} \\
&amp;=\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
v_{3} &amp; v_{2} &amp; v_{1} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)\left(\begin{array}{ccc}
\lambda_{3} &amp; 0 &amp; 0 \\
0 &amp; \lambda_{2} &amp; 0 \\
0 &amp; 0 &amp; \lambda_{1}
\end{array}\right)\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
v_{3} &amp; v_{2} &amp; v_{1} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)^{-1}
\end{aligned}
\]</span> 或者单纯缩放特征向量，也可以得到另外的对角化方式： <span
class="math display">\[
\begin{aligned}
A &amp;=\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
v_{1} &amp; v_{2} &amp; v_{3} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)\left(\begin{array}{ccc}
\lambda_{1} &amp; 0 &amp; 0 \\
0 &amp; \lambda_{2} &amp; 0 \\
0 &amp; 0 &amp; \lambda_{3}
\end{array}\right)\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
v_{1} &amp; v_{2} &amp; v_{3} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)^{-1} \\
&amp;=\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
c v_{1} &amp; v_{2} &amp; v_{3} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)\left(\begin{array}{ccc}
\lambda_{1} &amp; 0 &amp; 0 \\
0 &amp; \lambda_{2} &amp; 0 \\
0 &amp; 0 &amp; \lambda_{3}
\end{array}\right)\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
c v_{1} &amp; v_{2} &amp; v_{3} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)^{-1}
\end{aligned}
\]</span> 举一个具体的例子，比如对于<span
class="math inline">\(A=\left(\begin{array}{ll} 1 / 2 &amp; 3 / 2 \\ 3 /
2 &amp; 1 / 2
\end{array}\right)\)</span>，我们可以求得其特征值分别为-1、2，对应的特征值为[-1,
1]与[1, 1]，所以我们有： <span class="math display">\[
A=C D C^{-1} \quad \text { for } \quad C=\left(\begin{array}{cc}
-1 &amp; 1 \\
1 &amp; 1
\end{array}\right) \quad D=\left(\begin{array}{cc}
-1 &amp; 0 \\
0 &amp; 2
\end{array}\right)
\]</span> 或者 <span class="math display">\[
A=C^{\prime} D^{\prime}\left(C^{\prime}\right)^{-1} \quad \text { for }
\quad C^{\prime}=\left(\begin{array}{cc}
1 &amp; -1 \\
1 &amp; 1
\end{array}\right) \quad D^{\prime}=\left(\begin{array}{cc}
2 &amp; 0 \\
0 &amp; -1
\end{array}\right)
\]</span> 或者 <span class="math display">\[
A=C^{\prime\prime} D^{\prime\prime}\left(C^{\prime\prime}\right)^{-1}
\quad \text { for } \quad C^{\prime}=\left(\begin{array}{cc}
2 &amp; -1 \\
2 &amp; 1
\end{array}\right) \quad D^{\prime}=\left(\begin{array}{cc}
2 &amp; 0 \\
0 &amp; -1
\end{array}\right)
\]</span> 另外，留意到当<span
class="math inline">\(A\)</span>不可逆时，对角阵<span
class="math inline">\(D\)</span>上会有零。如对于$A=(
<span class="math display">\[\begin{array}{rr}
2 / 3 &amp; -4 / 3 \\
-2 / 3 &amp; 4 / 3
\end{array}\]</span>
<p>) $，我们有： <span class="math display">\[
A=C D C^{-1} \quad \text { for } \quad C=\left(\begin{array}{cc}
2 &amp; 1 \\
1 &amp; -1
\end{array}\right) \quad D=\left(\begin{array}{ll}
0 &amp; 0 \\
0 &amp; 2
\end{array}\right)
\]</span> 下面再给出一个矩阵不可对角化的例子。对于<span
class="math inline">\(A=\left(\begin{array}{lll} 1 &amp; 1 &amp; 0 \\ 0
&amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 2
\end{array}\right)\)</span>，其特征值为1、2，其1-特征空间为： <span
class="math display">\[
\left(A-I_{3}\right) v=0 \Longleftrightarrow\left(\begin{array}{lll}
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2
\end{array}\right)\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)=0 \Longleftrightarrow y=z=0
\]</span> 即x坐标轴。其2-特征空间为： <span class="math display">\[
\left(A-2 I_{3}\right) v=0 \Longleftrightarrow\left(\begin{array}{ccc}
-1 &amp; 1 &amp; 0 \\
0 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}\right)\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)=0 \Longleftrightarrow x=y=0
\]</span> 即z-坐标轴。所以该矩阵线性独立的特征向量只有两个（<span
class="math inline">\(&lt;n=3\)</span>），所以矩阵不可对角化。另外，矩阵是否可对角化与矩阵是否可逆没有关系。<br></p>
<p>为了更好理解可对角化矩阵，接下来我们再从几何角度对其进行讨论。上面说过，从几何上看，相似矩阵在不同的坐标系下执行相同的操作。而一个对角矩阵执行的操作其实很简单：对各个坐标轴执行缩放操作。综上，也就是说，对于一个可对角化矩阵（特化的相似矩阵），它在另一个坐标系下执行着对新的坐标轴执行缩放的操作；更具体地，对于一个可对角化的<span
class="math inline">\(n \times n\)</span>矩阵<span
class="math inline">\(A\)</span>，<span class="math inline">\(v_1, v_2,
..., v_n\)</span>是其线性独立的<span
class="math inline">\(n\)</span>个特征向量，那么<span
class="math inline">\(A\)</span>执行的线性变换的操作即为：在<span
class="math inline">\(v_i\)</span>向量方向上执行<span
class="math inline">\(\lambda_i\)</span>倍的缩放。于是，特征向量（方向）与特征值（大小）描述着一个矩阵执行的线性变换的重要特征。下面以两组不同特征值为例（<span
class="math inline">\(A = CDC^{-1}\)</span>）：<br> 1. 对于<span
class="math inline">\(A=\frac{1}{10}\left(\begin{array}{cc} 11 &amp; 6
\\ 9 &amp; 14 \end{array}\right)\)</span>，我们有<span
class="math inline">\(C=\left(\begin{array}{cc} 2 / 3 &amp; -1 \\ 1
&amp; 1 \end{array}\right)、 \quad D=\left(\begin{array}{cc} 2 &amp; 0
\\ 0 &amp; 1 / 2 \end{array}\right)\)</span>，也就是说，当<span
class="math inline">\(A\)</span>乘上一个向量，会使其在<span
class="math inline">\(\left(\begin{array}{cc} 2 / 3 \\ 1
\end{array}\right)\)</span>代表的方向上的坐标放大2倍，使其在<span
class="math inline">\(\left(\begin{array}{cc} -1 \\ 1
\end{array}\right)\)</span>代表的方向上的坐标缩小为1/2，如图所示，其中蓝色曲线表示<span
class="math inline">\(A\)</span>执行空间变换的大致方向：<br> <img
src="la-63.png" /><br> 2. 对于<span
class="math inline">\(A=\frac{1}{5}\left(\begin{array}{cc} 13 &amp; -2
\\ -3 &amp; 12 \end{array}\right)\)</span>，我们有<span
class="math inline">\(C=\left(\begin{array}{cc} 2 / 3 &amp; -1 \\ 1
&amp; 1 \end{array}\right)、 \quad D=\left(\begin{array}{ll} 2 &amp; 0
\\ 0 &amp; 3 \end{array}\right)\)</span>，也就是说，当<span
class="math inline">\(A\)</span>乘上一个向量，会使其在<span
class="math inline">\(\left(\begin{array}{cc} 2 / 3 \\ 1
\end{array}\right)\)</span>代表的方向上的坐标放大2倍，使其在<span
class="math inline">\(\left(\begin{array}{cc} -1 \\ 1
\end{array}\right)\)</span>代表的方向上的坐标放大3倍，如图所示，其中蓝色曲线表示<span
class="math inline">\(A\)</span>执行空间变换的大致方向：<br> <img
src="la-64.png" /><br>
以此类推，我们可以以特征向量和特征值去描述一个矩阵的线性空间变换行为。<br></p>
<p>在上面的讨论中，我们只允许实数特征值的出现，在这种情况下，我们会看到矩阵在执行的都是缩放操作。而如果我们允许虚数特征值的存在，情况又会是怎样的呢？下面我们对此进行讨论。<br>
首先我们先介绍如何求解得到复特征值和复特征向量。类似地，我们求解一个矩阵的特征行列式。对于一个<span
class="math inline">\(n \times n\)</span>的矩阵，其特征行列式也为<span
class="math inline">\(n\)</span>阶，则其对应的复特征值会有<span
class="math inline">\(n\)</span>个（虚部可能为0）。根据求得的复特征值，我们同样求解Null(<span
class="math inline">\(A-\lambda
I_n\)</span>)，即可得到复特征向量。下面以矩阵<span
class="math inline">\(A=\left(\begin{array}{cc} 1 &amp; -1 \\ 1 &amp; 1
\end{array}\right)\)</span>为例，我们先求得其特征行列式为： <span
class="math display">\[
f(\lambda)=\lambda^2-2\lambda+2
\]</span> 于是我们求解得到： <span class="math display">\[
\lambda=\frac{2 \pm \sqrt{4-8}}{2}=1 \pm i
\]</span> 我们先对第一个特征值<span
class="math inline">\(\lambda_1=1+i\)</span>求其相应特征向量： <span
class="math display">\[
A-(1+i) I_{2}=\left(\begin{array}{cc}
1-(1+i) &amp; -1 \\
1 &amp; 1-(1+i)
\end{array}\right)=\left(\begin{array}{cc}
-i &amp; -1 \\
1 &amp; -i
\end{array}\right)
\]</span> 再对其进行行列操作： <span class="math display">\[
\left(\begin{array}{cc}
-i &amp; -1 \\
1 &amp; -i
\end{array}\right) \stackrel{R_{2}=R_{2}-i
R_{1}}{\longrightarrow}\left(\begin{array}{cc}
-i &amp; -1 \\
0 &amp; 0
\end{array}\right) \stackrel{R_{1}=R_{1}
\div-i}{\longrightarrow}\left(\begin{array}{cc}
1 &amp; -i \\
0 &amp; 0
\end{array}\right)
\]</span> 于是我们得到<span
class="math inline">\(\left(\begin{array}{cc} x \\ y \end{array}\right)
= y\left(\begin{array}{cc} i \\ 1 \end{array}\right)\)</span>，即<span
class="math inline">\(\lambda_1\)</span>对应的特征向量<span
class="math inline">\(v_1 = \left(\begin{array}{cc} i \\ 1
\end{array}\right)\)</span>。同理对于<span
class="math inline">\(\lambda_2 = 1-i\)</span>，我们可以得到<span
class="math inline">\(v_2 = \left(\begin{array}{cc} -i \\ 1
\end{array}\right)\)</span>。<br>
另外，因为我们只考虑实数矩阵，那么特征行列式里的系数只会是实数，而对于系数为实数的多项式，其含虚数的复数解总是共轭出现的，如上面例子中的<span
class="math inline">\(\lambda_1=\bar{\lambda_2}\)</span>、<span
class="math inline">\(v_1=\bar{v_2}\)</span>。<br></p>
<p>接下来我们讨论复特征值和复特征向量的几何意义，先从一种简单但又很重要的矩阵开始——旋转缩放矩阵（rotation-scaling
matrices）讲起。其定义为一个有如下形式的<span class="math inline">\(2
\times 2\)</span>矩阵，其中<span class="math inline">\(a\)</span>与<span
class="math inline">\(b\)</span>都是实数且不都等于0： <span
class="math display">\[
\left(\begin{array}{cc}
a &amp; -b \\
b &amp; a
\end{array}\right)
\]</span> 对于这样一个矩阵，其可以视为一个旋转矩阵<span
class="math inline">\(R\)</span>（空间变换操作为将向量逆时针旋转角度<span
class="math inline">\(\theta\)</span>）与一个缩放矩阵<span
class="math inline">\(S\)</span>的乘积： <span class="math display">\[
R = \left(\begin{array}{cc}
\cos \theta &amp; -\sin \theta \\
\sin \theta &amp; \cos \theta
\end{array}\right) \quad \text {,} \quad S=\left(\begin{array}{ll}
r &amp; 0 \\
0 &amp; r
\end{array}\right) \text {. }
\]</span> 其中缩放系数<span class="math inline">\(r\)</span>： <span
class="math display">\[
r=\sqrt{\operatorname{det}(A)}=\sqrt{a^{2}+b^{2}}
\]</span>
也就是说，从几何上看，一个旋转缩放矩阵乘上一个向量，会对其进行一个角度<span
class="math inline">\(\theta\)</span>的旋转并对其缩放<span
class="math inline">\(r\)</span>倍。这样一个矩阵的特征值为<span
class="math inline">\(\lambda=a\pm bi\)</span>。下面还是以<span
class="math inline">\(A=\left(\begin{array}{cc} 1 &amp; -1 \\ 1 &amp; 1
\end{array}\right)\)</span>为例，我们可视化它的作用。首先<span
class="math inline">\(r=\sqrt{\operatorname{det}(A)}=\sqrt{2}\)</span>，接着<span
class="math inline">\(\cos \theta = a/r = 1/\sqrt{2}, \sin \theta = b/r
= 1/\sqrt{2}\)</span>，即<span class="math inline">\(\theta = 45
\degree\)</span>。所以矩阵<span
class="math inline">\(A\)</span>执行的空间变换：对向量进行<span
class="math inline">\(\sqrt{2}\)</span>倍的缩放并逆时针旋转<span
class="math inline">\(45\degree\)</span>，如下图所示：<br> <img
src="la-65.png" /><br> 但要注意的是，角度不能直接用<span
class="math inline">\(\arctan(·)\)</span>求解，因为其输出的角度只在第一四象限之间，如果旋转后的向量在第二三象限的话，我们会得到错误的角度。如对于矩阵<span
class="math inline">\(\left(\begin{array}{cc} -\sqrt{3} &amp; -1 \\ 1
&amp; -\sqrt{3} \end{array}\right)\)</span>旋转的角度为<span
class="math inline">\(150\degree\)</span>，但如果直接使用<span
class="math inline">\(\arctan(·)\)</span>求解我们会得到<span
class="math inline">\(-30\degree\)</span>。<br> <img
src="la-66.png" /><br></p>
<p>有复特征值和复特征向量的矩阵与旋转缩放矩阵又有什么关系呢？这就要引入旋转缩放定理：对于一个<span
class="math inline">\(2 \times 2\)</span>的实数矩阵<span
class="math inline">\(A\)</span>，其一个非实数复特征向量为<span
class="math inline">\(\lambda\)</span>，对应的特征向量为<span
class="math inline">\(v\)</span>，则对于： <span class="math display">\[
C=\left(\begin{array}{cc}
\mid &amp; \mid \\
\operatorname{Re}(v) &amp; \operatorname{Im}(v) \\
\mid &amp; \mid
\end{array}\right) \quad \text { and } \quad B=\left(\begin{array}{cc}
\operatorname{Re}(\lambda) &amp; \operatorname{Im}(\lambda) \\
-\operatorname{Im}(\lambda) &amp; \operatorname{Re}(\lambda)
\end{array}\right)
\]</span> 有<span
class="math inline">\(A=CBC^{-1}\)</span>（证明参见参考书籍5.5）。可以发现，<span
class="math inline">\(B\)</span>为一个旋转缩放矩阵。特别地，其对应的缩放系数为特征值的模<span
class="math inline">\(|\lambda|\)</span>。上式中Re与Im分别表示实部与虚部，即：
<span class="math display">\[
\operatorname{Re}(a+b i)=a \quad \operatorname{Im}(a+b i)=b \quad
\operatorname{Re}\left(\begin{array}{c}
x+y i \\
z+w i
\end{array}\right)=\left(\begin{array}{l}
x \\
z
\end{array}\right) \quad \operatorname{Im}\left(\begin{array}{l}
x+y i \\
z+w i
\end{array}\right)=\left(\begin{array}{l}
y \\
w
\end{array}\right)
\]</span> 下面以矩阵<span
class="math inline">\(A=\left(\begin{array}{cc} 2 &amp; -1 \\ 2 &amp; 0
\end{array}\right)\)</span>为例，介绍其表示的空间变换。首先我们可以求得其特征值<span
class="math inline">\(\lambda = 1\pm i\)</span>，取<span
class="math inline">\(\lambda = 1-i\)</span>求其特征向量为<span
class="math inline">\(v=\left(\begin{array}{c} 1 \\ 1+i
\end{array}\right)\)</span>。接着按照上面的定理我们对<span
class="math inline">\(A\)</span>进行分解，得到： <span
class="math display">\[
\begin{aligned}
C &amp;=\left(\operatorname{Re}\left(\begin{array}{c}
1 \\
1+i
\end{array}\right) \quad \operatorname{Im}\left(\begin{array}{c}
1 \\
1+i
\end{array}\right)\right)=\left(\begin{array}{ll}
1 &amp; 0 \\
1 &amp; 1
\end{array}\right) \\
B &amp;=\left(\begin{array}{cc}
\operatorname{Re}(\lambda) &amp; \operatorname{Im}(\lambda) \\
-\operatorname{Im}(\lambda) &amp; \operatorname{Re}(\lambda)
\end{array}\right)=\left(\begin{array}{cc}
1 &amp; -1 \\
1 &amp; 1
\end{array}\right)
\end{aligned}
\]</span> 由<span class="math inline">\(B\)</span>可以知道，矩阵<span
class="math inline">\(A\)</span>也是在进行一个与上面例子相同的旋转缩放操作，只不过是在<span
class="math inline">\(C\)</span>列向量对应坐标系下进行。更具体地，当<span
class="math inline">\(A\)</span>乘上一个向量，先将其转到一个新的坐标系下（<span
class="math inline">\(C^{-1}\)</span>），接着对其旋转缩放（<span
class="math inline">\(B\)</span>），之后再将其转回原来的坐标系下（<span
class="math inline">\(C\)</span>），如下图所示：<br> <img
src="la-67.png" /><br> 再以空间点为例子，将其可视化如下： <img
src="la-68.png" /><br> 图中橘色线表示每乘上一个<span
class="math inline">\(A\)</span>，空间点的变换方向。所以类似地，我们也可以讨论不同<span
class="math inline">\(\lambda\)</span>对应空间变换的意义。当矩阵<span
class="math inline">\(A\)</span>的<span
class="math inline">\(|\lambda|&gt;1\)</span>，不断乘上<span
class="math inline">\(A\)</span>会使得向量向外伸张，如下图所示：<br>
<img src="la-69.png" /><br> 而如果矩阵<span
class="math inline">\(A\)</span>的<span
class="math inline">\(|\lambda|=1\)</span>，不断乘上<span
class="math inline">\(A\)</span>会使得向量在一个椭圆环上旋转，如下图所示：<br>
<img src="la-70.png" /><br> 而如果矩阵<span
class="math inline">\(A\)</span>的<span
class="math inline">\(|\lambda|&lt;1\)</span>，不断乘上<span
class="math inline">\(A\)</span>会使得向量向原点收缩，如下图所示：<br>
<img src="la-71.png" /><br></p>
<p>以上的讨论我们都基于二维矩阵，而如果矩阵的维度更大的情况会如何？这边就要引入区块对角化定理（block
diagonalization theorem）。对于一个<span class="math inline">\(n \times
n\)</span>矩阵<span
class="math inline">\(A\)</span>，如果其特征向量的个数与特征值个数一致，那么其可以分解为<span
class="math inline">\(A=CBC^{-1}\)</span>，其中<span
class="math inline">\(B\)</span>是区块对角化矩阵，实特征值对应其对角线上一个数，一组共轭复特征值（选其中一个）对应其对角线上及附近的区块，<span
class="math inline">\(C\)</span>为它们各自对应的特征向量。以三维矩阵为例，假设其有一组复特征值（其中一个<span
class="math inline">\(\lambda_1\)</span>）与一个实特征值<span
class="math inline">\(\lambda_2\)</span>，那么其对应的<span
class="math inline">\(C\)</span>和<span
class="math inline">\(B\)</span>分别为：<br> <span
class="math display">\[
C=\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
\operatorname{Re}\left(v_{1}\right) &amp;
\operatorname{Im}\left(v_{1}\right) &amp; v_{2} \\
\mid &amp; \mid &amp; \mid
\end{array}\right) \quad B=\left(\begin{array}{ccc}
\operatorname{Re}\left(\lambda_{1}\right) &amp;
\operatorname{Im}\left(\lambda_{1}\right) &amp; 0 \\
-\operatorname{Im}\left(\lambda_{1}\right) &amp;
\operatorname{Re}\left(\lambda_{1}\right) &amp; 0 \\
0 &amp; 0 &amp; \lambda_{2}
\end{array}\right)
\]</span> 举一个实例，如对于矩阵<span
class="math inline">\(A=\frac{1}{29}\left(\begin{array}{ccc} 33 &amp;
-23 &amp; 9 \\ 22 &amp; 33 &amp; -23 \\ 19 &amp; 14 &amp; 50
\end{array}\right)\)</span>，其特征值为<span
class="math inline">\(\lambda_1 = 1-i, \bar{\lambda_1} = 1+i,
\lambda_2=2\)</span>，根据特征值又可以求得<span
class="math inline">\(v_{1}=\left(\begin{array}{c} -7-i \\ 2-9 i \\ 5
\end{array}\right), v_{2}=\left(\begin{array}{c} 2 \\ -1 \\ 3
\end{array}\right)\)</span>。所以<span
class="math inline">\(A=CBC^{-1}\)</span>，其中： <span
class="math display">\[
\begin{array}{l}
C=\left(\begin{array}{ccc}
\mid &amp; \mid &amp; \mid \\
\operatorname{Re}\left(v_{1}\right) &amp;
\operatorname{Im}\left(v_{1}\right) &amp; v_{2} \\
\mid &amp; \mid &amp; \mid
\end{array}\right)=\left(\begin{array}{ccc}
-7 &amp; -1 &amp; 2 \\
2 &amp; -9 &amp; -1 \\
5 &amp; 0 &amp; 3
\end{array}\right) \\
B=\left(\begin{array}{ccc}
\operatorname{Re}\left(\lambda_{1}\right) &amp;
\operatorname{Im}\left(\lambda_{1}\right) &amp; 0 \\
-\operatorname{Im}\left(\lambda_{1}\right) &amp;
\operatorname{Re}\left(\lambda_{1}\right) &amp; 0 \\
0 &amp; 0 &amp; 2
\end{array}\right)=\left(\begin{array}{ccc}
1 &amp; -1 &amp; 0 \\
1 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 2
\end{array}\right) .
\end{array}
\]</span> 矩阵<span
class="math inline">\(B\)</span>表示的意义是在标准坐标系xy轴方向上对向量旋转<span
class="math inline">\(45\degree\)</span>并缩放<span
class="math inline">\(\sqrt{2}\)</span>倍，并对z轴上缩放<span
class="math inline">\(2\)</span>倍。矩阵<span
class="math inline">\(A\)</span>执行的是相同的操作，只是在<span
class="math inline">\(C\)</span>对应的坐标系下完成。<br></p>
<h2 id="正交性orthogonality">11. 正交性（Orthogonality）</h2>
<p>正交性也是线性代数中很重要的一个概念。我们为什么要在最后提到它呢？它有什么用呢？下面我们将对此进行讨论。<br></p>
<p>说到正交，我们很容易就联想到我们高中就学过的点积运算，对两个向量<span
class="math inline">\(x, y\)</span>而言： <span class="math display">\[
x \cdot y=\left(\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{array}\right) \cdot\left(\begin{array}{c}
y_{1} \\
y_{2} \\
\vdots \\
y_{n}
\end{array}\right)=x_{1} y_{1}+x_{2} y_{2}+\cdots+x_{n} y_{n} .
\]</span> 当向量<span class="math inline">\(x,
y\)</span>满足下面条件，我们有<span class="math inline">\(x,
y\)</span>正交： <span class="math display">\[
x·y = \|x\|\|y\|\cos \alpha = 0
\]</span> 其中<span class="math inline">\(\alpha为向量\)</span>x, y<span
class="math inline">\(之间的夹角，\)</span><span
class="math inline">\(\|·\|\)</span>表示向量的长度： <span
class="math display">\[
\|x\|=\sqrt{x \cdot x}=\sqrt{x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2}}
\]</span>
长度为1的向量被称为单位向量。另外两点之间的距离即它们组成向量的长度：
<span class="math display">\[
\operatorname{dist}(x, y)=\|y-x\|
\]</span></p>
<p>在知道了两个向量的正交条件之后，进一步地，我们讨论对于一个子空间的正交——<strong>正交补空间（Orthogonal
Complement）</strong>。对于<span
class="math inline">\(R^n\)</span>的子空间<span
class="math inline">\(W\)</span>而言，其正交补空间为： <span
class="math display">\[
W^{\perp}=\left\{v \text { in } \mathbf{R}^{n} \mid v \cdot w=0 \text {
for all } w \text { in } W\right\}
\]</span> 也就是说，<span
class="math inline">\(W^{\perp}\)</span>是正交于<span
class="math inline">\(W\)</span>中所有向量的所有<span
class="math inline">\(R^n\)</span>中的向量的集合。例如，在<span
class="math inline">\(R^2\)</span>里一条直线的正交补空间是与它垂直的一条直线，在<span
class="math inline">\(R^3\)</span>中一条直线的正交补空间是与它垂直的一个平面，在<span
class="math inline">\(R^3\)</span>中一个平面的正交补空间是与它垂直的一条直线。<br>
<img src="la-72.png" /><br> 从上图我们也可以看出，$(W<sup>{})</sup>{}=W,
(W)+(W^{})=n <span
class="math inline">\(。在明确正交补空间的概念之后，接下来我们介绍如何计算它。首先设定\)</span>W<span
class="math inline">\(是矩阵\)</span>A<span
class="math inline">\(的列空间（\)</span>W=(A)$），则有（证明参见参考书籍6.2）：
<span class="math display">\[
W^{\perp}=\text{Nul}(A^T)
\]</span> 举个例子，比如对于<span class="math inline">\(v_1,
v_2\)</span>张成的空间（我们可以将它们拼接成一个矩阵，即可以将它们理解为一个矩阵的列空间）：
<span class="math display">\[
v_{1}=\left(\begin{array}{l}
1 \\
7 \\
2
\end{array}\right) \quad v_{2}=\left(\begin{array}{c}
-2 \\
3 \\
1
\end{array}\right)
\]</span> 其正交补空间为： <span class="math display">\[
\text{Nul} \left(\begin{array}{l}
-v_{1}^{T}- \\
-v_{2}^{T}-
\end{array}\right)=\text{Nul} \left(\begin{array}{ccc}
1 &amp; 7 &amp; 2 \\
-2 &amp; 3 &amp; 1
\end{array}\right)
\]</span> 即求解下列方程组： <span class="math display">\[
\left\{\begin{aligned}
x_{1}+7 x_{2}+2 x_{3} &amp;=0 \\
-2 x_{1}+3 x_{2}+x_{3} &amp;=0 .
\end{aligned}\right.
\]</span> 最终我们可以计算得到： <span class="math display">\[
W^{\perp}=\operatorname{Span}\left\{\left(\begin{array}{c}
1 \\
-5 \\
17
\end{array}\right)\right\}
\]</span> 而如果我们考虑矩阵<span
class="math inline">\(A\)</span>的行空间<span
class="math inline">\(\text{Row}(A)=\text{Col}(A^T)\)</span>，则有<span
class="math inline">\(\operatorname{Row}(A)^{\perp}=\operatorname{Nul}(A)\)</span>。总结有：
<span class="math display">\[
\begin{aligned}
\operatorname{Row}(A)^{\perp} &amp;=\operatorname{Nul}(A) &amp;
\operatorname{Nul}(A)^{\perp} &amp;=\operatorname{Row}(A) \\
\operatorname{Col}(A)^{\perp} &amp;=\operatorname{Nul}\left(A^{T}\right)
&amp; \operatorname{Nul}\left(A^{T}\right)^{\perp}
&amp;=\operatorname{Col}(A) .
\end{aligned}
\]</span>
利用上述的性质，我们有时候可以很方便地求解正交补空间。如求解矩阵<span
class="math inline">\(A=\left(\begin{array}{ccc} 2 &amp; 4 &amp; -1 \\ 3
&amp; 2 &amp; 0 \\ -2 &amp; 4 &amp; 3
\end{array}\right)\)</span>的5-特征空间的正交补空间：<br>
先求解5-特征空间： <span class="math display">\[
W=\operatorname{Nul}\left(A-5
I_{3}\right)=\operatorname{Nul}\left(\begin{array}{ccc}
-3 &amp; 4 &amp; -1 \\
3 &amp; -3 &amp; 0 \\
-2 &amp; 4 &amp; -2
\end{array}\right)
\]</span> 所以我们直接有： <span class="math display">\[
W^{\perp}=\operatorname{Row}\left(\begin{array}{ccc}
-3 &amp; 4 &amp; -1 \\
3 &amp; -3 &amp; 0 \\
-2 &amp; 4 &amp; -2
\end{array}\right)=\operatorname{Span}\left\{\left(\begin{array}{c}
-3 \\
4 \\
-1
\end{array}\right),\left(\begin{array}{c}
3 \\
-3 \\
0
\end{array}\right),\left(\begin{array}{c}
-2 \\
4 \\
-2
\end{array}\right)\right\}
\]</span></p>
<p>所以对于<span class="math inline">\(R^n\)</span>中某个向量<span
class="math inline">\(x\)</span>，其可以分解为在<span
class="math inline">\(R^n\)</span>中一个子空间<span
class="math inline">\(W\)</span>上的投影<span
class="math inline">\(x_W\)</span>及其正交补空间<span
class="math inline">\(W^{\perp}\)</span>上的一个向量<span
class="math inline">\(x_{W^{\perp}}\)</span>之和，如下图所示，向量<span
class="math inline">\(x\)</span>到子空间<span
class="math inline">\(W\)</span>的距离即为<span
class="math inline">\(\|x_{W^{\perp}}\|\)</span>。<br> <img
src="la-73.png" /><br></p>
<p>接下来我们讨论如何求解<span class="math inline">\(x_W\)</span>与<span
class="math inline">\(x_{W^{\perp}}\)</span>。这里要引入一个定理（证明见参考书籍6.3）：设<span
class="math inline">\(W=\operatorname{Col}(A)\)</span>，<span
class="math inline">\(A\)</span>为一个<span class="math inline">\(m
\times n\)</span>矩阵，<span class="math inline">\(x\)</span>为<span
class="math inline">\(R^m\)</span>中一个向量，则有： <span
class="math display">\[
A^TAc = A^Tx
\]</span> 其中，<span
class="math inline">\(c\)</span>为待求解的未知向量，<span
class="math inline">\(x_W=Ac\)</span>，<span
class="math inline">\(x_{W^{\perp}}=x-x_W\)</span>。举个例子，设<span
class="math inline">\(L=\operatorname{Span}\{u\}\)</span>是<span
class="math inline">\(R^n\)</span>中一条直线，<span
class="math inline">\(x\)</span>是<span
class="math inline">\(R^n\)</span>中一个向量，求解其在<span
class="math inline">\(L\)</span>上的投影<span
class="math inline">\(x_L\)</span>。于是我们的问题变为求解<span
class="math inline">\(u^Tuc=u^Tx\)</span>。在一维的情况下，<span
class="math inline">\(u^Tu=u·u， u^Tx=u·x\)</span>，所以： <span
class="math display">\[
x_L=uc=\frac{(u·x)}{(u·u)}u
\]</span> 如下图所示：<br> <img src="la-74.png" /><br> 而当<span
class="math inline">\(W\)</span>维度更高不只是一条直线，我们要做的也很简单：首先求解<span
class="math inline">\(A^TA\)</span>与<span
class="math inline">\(A^Tx\)</span>，然后求解线性方程组得到<span
class="math inline">\(c\)</span>，然后就可以得到<span
class="math inline">\(x_W=Ac，x_{W^{\perp}}=x-x_W\)</span>。举个例子，比如在<span
class="math inline">\(R^3\)</span>中将向量<span
class="math inline">\(x\)</span>投影到一个二维平面<span
class="math inline">\(W\)</span>： <span class="math display">\[
W=\operatorname{Span}\left\{\left(\begin{array}{c}
1 \\
0 \\
-1
\end{array}\right),\left(\begin{array}{l}
1 \\
1 \\
0
\end{array}\right)\right\} \quad x=\left(\begin{array}{l}
1 \\
2 \\
3
\end{array}\right)
\]</span> 首先求解<span class="math inline">\(A^TA\)</span>与<span
class="math inline">\(A^Tx\)</span>： <span class="math display">\[
A^{T} A=\left(\begin{array}{ll}
2 &amp; 1 \\
1 &amp; 2
\end{array}\right) \quad A^{T} x=\left(\begin{array}{c}
-2 \\
3
\end{array}\right)
\]</span> 接着求解<span class="math inline">\(c\)</span>： <span
class="math display">\[
\left(\begin{array}{ll|r}
2 &amp; 1 &amp; -2 \\
1 &amp; 2 &amp; 3
\end{array}\right)
\stackrel{\mathrm{RREF}}{\longrightarrow}\left(\begin{array}{ll|r}
1 &amp; 0 &amp; -7 / 3 \\
0 &amp; 1 &amp; 8 / 3
\end{array}\right) \Longrightarrow c=\frac{1}{3}\left(\begin{array}{c}
-7 \\
8
\end{array}\right)
\]</span> 于是我们得到： <span class="math display">\[
x_{W}=A c=\frac{1}{3}\left(\begin{array}{l}
1 \\
8 \\
7
\end{array}\right) \quad
x_{W^{\perp}}=x-x_{W}=\frac{1}{3}\left(\begin{array}{c}
2 \\
-2 \\
2
\end{array}\right)
\]</span> 将其可视化如下图所示：<br> <img src="la-75.png" /><br></p>
<p>接下来我们换个角度去思考正交投影这个问题，它本身是一个线性空间变换，那其背后的矩阵应该是什么呢？这里的逻辑其实也很简单，只要我们对原来空间的基向量分别投影到新的空间中，我们就可以知道每个维度上的空间变换，拼接起来就得到正交投影对应的矩阵。举个例子，比如我们要得到代表将<span
class="math inline">\(R^3\)</span>中标准正交基表示的向量正交投影到直线<span
class="math inline">\(W=\operatorname{Span}\{u\}\)</span>上的矩阵<span
class="math inline">\(B\)</span>，其中： <span class="math display">\[
u=\left(\begin{array}{c}
-1 \\
1 \\
1
\end{array}\right)
\]</span> 那么我们要求的就是<span class="math inline">\((e_1)_L,
(e_2)_L, (e_3)_L\)</span>，根据我们上面得到的公式： <span
class="math display">\[
\left.\begin{array}{l}
\left(e_{1}\right)_{L}=\frac{u \cdot e_{1}}{u \cdot u}
u=\frac{1}{3}\left(\begin{array}{c}
1 \\
-1 \\
-1
\end{array}\right) \\
\left(e_{2}\right)_{L}=\frac{u \cdot e_{2}}{u \cdot u}
u=\frac{1}{3}\left(\begin{array}{c}
-1 \\
1 \\
1
\end{array}\right) \\
\left(e_{3}\right)_{L}=\frac{u \cdot e_{3}}{u \cdot u}
u=\frac{1}{3}\left(\begin{array}{c}
-1 \\
1 \\
1
\end{array}\right)
\end{array}\right\} \quad \Longrightarrow \quad
B=\frac{1}{3}\left(\begin{array}{ccc}
1 &amp; -1 &amp; -1 \\
-1 &amp; 1 &amp; 1 \\
-1 &amp; 1 &amp; 1
\end{array}\right)
\]</span> 类似地，再考虑上面将向量投影到<span
class="math inline">\(R^3\)</span>中二维平面的例子： <span
class="math display">\[
W=\operatorname{Span}\left\{\left(\begin{array}{c}
1 \\
0 \\
-1
\end{array}\right),\left(\begin{array}{l}
1 \\
1 \\
0
\end{array}\right)\right\}
\]</span> 要求其背后的变换矩阵，我们依次求解<span
class="math inline">\((e_1)_W, (e_2)_W,
(e_3)_W\)</span>。我们先求解<span
class="math inline">\(A^TA\)</span>与<span
class="math inline">\(A^Te_i\)</span>，然后求解<span
class="math inline">\(c\)</span>，接着我们就能得到<span
class="math inline">\((e_i)_W=Ac\)</span>： <span
class="math display">\[
\left(\begin{array}{ll|l}
2 &amp; 1 &amp; 1 \\
1 &amp; 2 &amp; 1
\end{array}\right)
\stackrel{\mathrm{RREF}}{\longrightarrow}\left(\begin{array}{ll|l}
1 &amp; 0 &amp; 1 / 3 \\
0 &amp; 1 &amp; 1 / 3
\end{array}\right)
\Longrightarrow\left(e_{1}\right)_{W}=A\left(\begin{array}{c}
1 / 3 \\
1 / 3
\end{array}\right)=\frac{1}{3}\left(\begin{array}{c}
2 \\
1 \\
-1
\end{array}\right)
\]</span> <span class="math display">\[
\left(\begin{array}{ll|l}
2 &amp; 1 &amp; 0 \\
1 &amp; 2 &amp; 1
\end{array}\right)
\stackrel{\mathrm{RREF}}{\longrightarrow}\left(\begin{array}{ll|r}
1 &amp; 0 &amp; -1 / 3 \\
0 &amp; 1 &amp; 2 / 3
\end{array}\right)
\Longrightarrow\left(e_{2}\right)_{W}=A\left(\begin{array}{c}
-1 / 3 \\
2 / 3
\end{array}\right)=\frac{1}{3}\left(\begin{array}{l}
1 \\
2 \\
1
\end{array}\right)
\]</span> <span class="math display">\[
\left(\begin{array}{ll|r}
2 &amp; 1 &amp; -1 \\
1 &amp; 2 &amp; 0
\end{array}\right) \stackrel{\text { RREF
}}{\longrightarrow}\left(\begin{array}{ll|r}
1 &amp; 0 &amp; -2 / 3 \\
0 &amp; 1 &amp; 1 / 3
\end{array}\right)
\Longrightarrow\left(e_{3}\right)_{W}=A\left(\begin{array}{c}
-2 / 3 \\
1 / 3
\end{array}\right)=\frac{1}{3}\left(\begin{array}{c}
-1 \\
1 \\
2
\end{array}\right)
\]</span> 将它们拼接起来，我们可以得到求解的正交投影变换矩阵<span
class="math inline">\(B\)</span>： <span class="math display">\[
B=\frac{1}{3}\left(\begin{array}{ccc}
2 &amp; 1 &amp; -1 \\
1 &amp; 2 &amp; 1 \\
-1 &amp; 1 &amp; 2
\end{array}\right)
\]</span> 或者我们直接从代数角度出发，根据上面的定理，我们有： <span
class="math display">\[
x_{W}=A\left(A^{T} A\right)^{-1} A^{T} x
\]</span> 那么正交投影变换矩阵即为：<span class="math inline">\(B =
A\left(A^{T} A\right)^{-1} A^{T}\)</span>。<br></p>
<p>那么代表着将向量投影到空间<span
class="math inline">\(W\)</span>的正交投影变换矩阵<span
class="math inline">\(B\)</span>有什么性质呢？<br> 1. <span
class="math inline">\(\operatorname{Col}(B)=W\)</span>，任何向量经过<span
class="math inline">\(B\)</span>变换后都在<span
class="math inline">\(W\)</span>上；<br> 2. <span
class="math inline">\(\operatorname{Nul}(B)=W^{\perp}\)</span>，<span
class="math inline">\(W^{\perp}\)</span>上的向量经过<span
class="math inline">\(B\)</span>变换后都为0向量；<br> 3. <span
class="math inline">\(B^n=B\)</span>，一个向量经过<span
class="math inline">\(B\)</span>变换到<span
class="math inline">\(W\)</span>上后，再经过<span
class="math inline">\(B\)</span>变换会维持不变（<span
class="math inline">\(W\)</span>上的向量正交投影仍是其自身）；<br> 4.
如果<span class="math inline">\(W \neq 0\)</span>，那么1是<span
class="math inline">\(B\)</span>的特征值，<span
class="math inline">\(W\)</span>就是<span
class="math inline">\(B\)</span>的1-特征空间；<br> 5. 如果<span
class="math inline">\(W \neq R^n\)</span>，那么0是<span
class="math inline">\(B\)</span>的特征值，<span
class="math inline">\(W^{\perp}\)</span>就是<span
class="math inline">\(B\)</span>的0-特征空间；<br> 6. <span
class="math inline">\(B\)</span>与对角线上有<span
class="math inline">\(m\)</span>个1与<span
class="math inline">\(n-m\)</span>个0的对角阵相似，其中<span
class="math inline">\(m\)</span>是<span
class="math inline">\(W\)</span>维度，<span
class="math inline">\(n\)</span>为空间维度。<br></p>
<p>基于这些性质，我们对上面例子的的正交投影矩阵<span
class="math inline">\(B\)</span>做进一步讨论，首先可以验证： <span
class="math display">\[
B^n = B=\frac{1}{3}\left(\begin{array}{ccc}
2 &amp; 1 &amp; -1 \\
1 &amp; 2 &amp; 1 \\
-1 &amp; 1 &amp; 2
\end{array}\right)
\]</span> 接着我们可以求解<span
class="math inline">\(W^{\perp}=\operatorname{Nul}(B)\)</span>，有：
<span class="math display">\[
W^{\perp}=\operatorname{Span}\left\{\left(\begin{array}{c}
1 \\
-1 \\
1
\end{array}\right)\right\}
\]</span> 又我们已知（或者再通过<span
class="math inline">\(W=\operatorname{Col}(B)\)</span>求解）： <span
class="math display">\[
W=\operatorname{Span}\left\{\left(\begin{array}{c}
1 \\
0 \\
-1
\end{array}\right),\left(\begin{array}{l}
1 \\
1 \\
0
\end{array}\right)\right\}
\]</span> 那么我们就可以直接写出其特征分解式： <span
class="math display">\[
B=\left(\begin{array}{ccc}
1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; -1 \\
-1 &amp; 0 &amp; 1
\end{array}\right)\left(\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{array}\right)\left(\begin{array}{ccc}
1 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; -1 \\
-1 &amp; 0 &amp; 1
\end{array}\right)^{-1}
\]</span></p>
<p>接着我们考虑一种特殊情况，<span
class="math inline">\(W\)</span>中已知的基为正交基（<span
class="math inline">\(\left\{u_{1}, u_{2}, \ldots,
u_{m}\right\}\)</span>，每两个向量点乘都为0），那我们可以很轻易地写出<span
class="math inline">\(x_W\)</span>的形式： <span class="math display">\[
x_{W}=\frac{x \cdot u_{1}}{u_{1} \cdot u_{1}} u_{1}+\frac{x \cdot
u_{2}}{u_{2} \cdot u_{2}} u_{2}+\cdots+\frac{x \cdot u_{m}}{u_{m} \cdot
u_{m}} u_{m}
\]</span> 这个公式其实很好理解，<span class="math inline">\(x \cdot u_i
= \|x\|\cos(\theta)\|u_i\|\)</span>，其中<span
class="math inline">\(\|x\|\cos(\theta)\)</span>表示<span
class="math inline">\(x\)</span>投影到<span
class="math inline">\(u_i\)</span>方向的长度，所以<span
class="math inline">\(\frac{x \cdot u_{i}}{u_{i} \cdot u_{i}}
u_{i}=\|x\|\cos(\theta) \frac{u_i}{\|u_i\|}\)</span>，<span
class="math inline">\(\frac{u_i}{\|u_i\|}\)</span>为单位向量，即该式表示<span
class="math inline">\(x\)</span>分解后在<span
class="math inline">\(u_i\)</span>方向上的向量，而这些分解后的向量相加之后即可得到<span
class="math inline">\(x\)</span>。而如果已知的基为标准正交基（每两个向量点乘都为0，向量的大小为1），则这个公式会变得更加简单：
<span class="math display">\[
x_{W}=\left(x \cdot u_{1}\right) u_{1}+\left(x \cdot u_{2}\right)
u_{2}+\cdots+\left(x \cdot u_{m}\right) u_{m}
\]</span> 下面举个例子，比如要将<span
class="math inline">\(x\)</span>转到以<span
class="math inline">\(\mathcal{B}\)</span>为基的空间中得到<span
class="math inline">\(x_{\mathcal{B}}\)</span>，其中： <span
class="math display">\[
\mathcal{B}=\left\{\left(\begin{array}{l}
1 \\
2
\end{array}\right),\left(\begin{array}{c}
-4 \\
2
\end{array}\right)\right\} \quad x=\left(\begin{array}{l}
0 \\
3
\end{array}\right)
\]</span> 因为<span class="math inline">\(\mathcal{B}\)</span>中<span
class="math inline">\(u_1, u_2\)</span>是正交的，我们直接有： <span
class="math display">\[
x_{\mathcal{B}}=\left(\frac{x \cdot u_{1}}{u_{1} \cdot u_{1}}, \frac{x
\cdot u_{2}}{u_{2} \cdot u_{2}}\right)=\left(\frac{3 \cdot
2}{1^{2}+2^{2}}, \frac{3 \cdot
2}{(-4)^{2}+2^{2}}\right)=\left(\frac{6}{5}, \frac{3}{10}\right)
\]</span> 如下图所示：<br> <img src="la-76.png" /><br>
从上面的讨论中，我们可以看到如果知道一个子空间的正交基，要求一个向量到其上的投影是很简便的。那么，如果我们只知道一个子空间的不正交的基，我们有没有可能将它们转换为一组等价的正交基呢？这我们就要引入Gram-Schmidt过程：假设<span
class="math inline">\(\left\{v_{1}, v_{2}, \ldots,
v_{m}\right\}\)</span>为<span
class="math inline">\(R^n\)</span>子空间的<span
class="math inline">\(W\)</span>的一组基，定义： <span
class="math display">\[
\begin{aligned}
&amp;1.   u_{1}=v_{1} \\
&amp;2.   u_{2}=\left(v_{2}\right)_{\operatorname{span}\left\{u_{1}\right\}^{\perp}}
\quad=v_{2}-\frac{v_{2} \cdot u_{1}}{u_{1} \cdot u_{1}} u_{1} \\
&amp;3.  u_{3}=\left(v_{3}\right)_{\text {span }\left\{u_{1},
u_{2}\right\}^{\perp}} \quad=v_{3}-\frac{v_{3} \cdot u_{1}}{u_{1} \cdot
u_{1}} u_{1}-\frac{v_{3} \cdot u_{2}}{u_{2} \cdot u_{2}} u_{2}\\
&amp; \vdots \\
&amp;m.  u_{m}=\left(v_{m}\right)_{\operatorname{span}\left\{u_{1},
u_{2}, \ldots, u_{m-1}\right\}^{\perp}}=v_{m}-\sum_{i=1}^{m-1}
\frac{v_{m} \cdot u_{i}}{u_{i} \cdot u_{i}} u_{i} \\
\end{aligned}
\]</span> 这样我们得到的<span class="math inline">\(\left\{u_{1}, u_{2},
\ldots, u_{m}\right\}\)</span>就是<span
class="math inline">\(W\)</span>的一组正交基。举个例子，比如对于<span
class="math inline">\(W=\operatorname{Span}\left\{v_{1}, v_{2},
v_{3}\right\}=\mathbf{R}^{3}\)</span>，其中： <span
class="math display">\[
v_{1}=\left(\begin{array}{l}
1 \\
1 \\
0
\end{array}\right) \quad v_{2}=\left(\begin{array}{l}
1 \\
1 \\
1
\end{array}\right) \quad v_{3}=\left(\begin{array}{l}
3 \\
1 \\
1
\end{array}\right)
\]</span> 基于上面的Gram-Schmidt过程，我们有： <img
src="la-77.png" /><br> 当然，如果在这个过程中，<span
class="math inline">\(\left\{v_{1}, v_{2}, \ldots,
v_{m}\right\}\)</span>存在线性依赖项，则我们可能得到<span
class="math inline">\(u_i=0\)</span>，这时候我们丢弃<span
class="math inline">\(u_i\)</span>即可。<br></p>
<p>所以总结一下，到目前为止，我们有两种方式去求解一个向量<span
class="math inline">\(x\)</span>正交投影到子空间<span
class="math inline">\(W\)</span>上的向量<span
class="math inline">\(x_W\)</span>：一种需要我们进行矩阵行操作（<span
class="math inline">\(A^TAc=A^Tx,
x_W=Ac\)</span>），另一种则需要一组正交基（直接投影到正交基的各个基上进行组合）。<br></p>
<p>最后简单介绍一下，如果方程<span
class="math inline">\(Ax=b\)</span>无解，我们如何通过最小二乘法求解其最优近似解。我们首先在几何上理解这个问题：既然<span
class="math inline">\(Ax=b\)</span>无解，那么<span
class="math inline">\(b\)</span>不在<span
class="math inline">\(\operatorname{Col}(A)\)</span>空间中，我们将其投影到<span
class="math inline">\(\operatorname{Col}(A)\)</span>上得到<span
class="math inline">\(b_{\operatorname{Col}(A)}\)</span>，于是我们的问题就变为求解<span
class="math inline">\(A\hat
x=b_{\operatorname{Col}(A)}\)</span>，其中<span
class="math inline">\(\hat x\)</span>为我们要求的近似最优解。假设<span
class="math inline">\(v_1, v_2, \ldots, v_n\)</span>为<span
class="math inline">\(A\)</span>的列向量，则有： <span
class="math display">\[
A \widehat{x}=A\left(\begin{array}{c}
\widehat{x}_{1} \\
\widehat{x}_{2} \\
\vdots \\
\widehat{x}_{n}
\end{array}\right)=\widehat{x}_{1} v_{1}+\widehat{x}_{2}
v_{2}+\cdots+\widehat{x}_{n} v_{n}
\]</span> 上述各变量的关系如下图所示：<br> <img src="la-78.png" /><br>
也就是说，只要应用上面我们讨论的正交投影的方法得到<span
class="math inline">\(b_{\operatorname{Col}(A)}\)</span>，接下来我们需要做的就是求解方程组<span
class="math inline">\(A\hat
x=b_{\operatorname{Col}(A)}\)</span>。当然，如果<span
class="math inline">\(A\)</span>的列向量的个数高于子空间<span
class="math inline">\(\operatorname{Col}(A)\)</span>的维度，则方程的解不唯一，如下图所示：<br>
<img src="la-79.png" /><br>
在实际应用中，我们需要做的就是把任意函数中未知的参数（一次函数、二次函数、三角函数...）视为<span
class="math inline">\(x\)</span>，数据构成矩阵<span
class="math inline">\(A\)</span>与向量<span
class="math inline">\(b\)</span>，接着就可以进行求解了。下面给出一个简单的例子：求拟合数据点<span
class="math inline">\((-1, 1/2), (-1, 1), (2, -1/2), (3,
2)\)</span>的最优二次函数<span
class="math inline">\(y=Bx^2+Cx+D\)</span>。代入数据，我们有： <span
class="math display">\[
\begin{aligned}
\frac{1}{2} &amp;=B(-1)^{2}+C(-1)+D \\
-1 &amp;=B(1)^{2}+C(1)+D \\
-\frac{1}{2} &amp;=B(2)^{2}+C(2)+D \\
2 &amp;=B(3)^{2}+C(3)+D
\end{aligned}
\]</span> 于是： <span class="math display">\[
A=\left(\begin{array}{rrr}
1 &amp; -1 &amp; 1 \\
1 &amp; 1 &amp; 1 \\
4 &amp; 2 &amp; 1 \\
9 &amp; 3 &amp; 1
\end{array}\right) \quad x=\left(\begin{array}{l}
B \\
C \\
D
\end{array}\right) \quad b=\left(\begin{array}{r}
1 / 2 \\
-1 \\
-1 / 2 \\
2
\end{array}\right)
\]</span>
这样我们就定义出了一个求最优近似解的方程组，应用上面我们讨论的正交投影的方法，可以得到<span
class="math inline">\(B, C, D\)</span>大小，即有： <span
class="math display">\[
y=\frac{53}{88} x^{2}-\frac{379}{440} x-\frac{41}{44}
\]</span></p>
<hr />
<blockquote>
<p>参考书籍：Interactive Linear Algebra - by Dan Margalit, Joseph
Rabinoff (https://textbooks.math.gatech.edu/ila/index2.html)</p>
</blockquote>

        
            <div class="donate-container">
    <div class="donate-button">
        <button id="donate-button">赞赏</button>
    </div>
    <div class="donate-img-container hide" id="donate-img-container">
        <img id="donate-img" src="" data-src="/img/donate.jpg">
        <p> 感谢鼓励 </p>
    </div>
</div>
        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        
        <li>
            <a target="_blank"  href="https://www.linkedin.com/in/腾俊-刘-08bb61180">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-linkedin"></i>
                            </span>
            </a>
        </li>
        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a target="_blank" rel="noopener" href="https://niexiaotao.com">Xiaotao&#39;s Page</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>  Theme <a target="_blank" rel="noopener" href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




  

    
      <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-MML-AM_CHTML"></script>
      <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
            processEscapes: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
        });
      </script>
      <script type="text/x-mathjax-config">
        MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for (i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
          }
        });
      </script>
    

    

  


</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




    <script type="text/javascript">
       (function() {
           if (typeof LivereTower === 'function') { return; }

           var j, d = document.getElementById('lv-container');

           d.setAttribute('data-id','city');
           d.setAttribute('data-uid' , 'MTAyMC81Mzc3MS8zMDI0NA==');

           j = document.createElement('script');
           j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
           j.async = true;

           d.appendChild(j);
       })();
    </script>
    <noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
    </div>

</html>
